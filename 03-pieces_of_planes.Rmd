# Pieces of Planes

Whereas the last chapter discussed one-dimensional maps whose graphs are segments of lines, this chapter deals with two-dimensional maps whose graphs are pieces of planes and which thus produce much more interesting displays. This chapter provides the minimum tools for creating attractors that genuinely qualify as art. Armed with only the information contained here, you have such a great variety of available patterns that you hardly need to proceed beyond this chapter. But if you do stop here, you miss some delightful surprises.

## Quadratic Maps in Two Dimensions 

In the discussion so far, the maps have involved a single variable X whose value changes with each iteration of the equation. Such maps are said to be onedimensional because the values of X can be thought of as lying along a line, and a line is a one-dimensional object. By plotting each value of X versus a previous value of X, the line can be made to wiggle with considerable complexity; but it always remains a line, and lines are of limited interest and beauty.

The situation is more interesting when you consider iterated maps that involve two variables, X and Y. In such a case, each iterate produces a point in a plane, where X, by convention, represents the horizontal coordinate of the point, and Y represents the vertical coordinate. With successive iteration, the points fill in some portion of the plane. The visually interesting cases, as usual, are the chaotic ones.

Such two-dimensional maps might arise, for example, from an ecological model only slightly more complicated than the logistic equation. A classic example is the predator-prey problem in which X represents the prey and Y the predator. In a simple linear model, the solution is a fixed point (a unique number of both predators and prey) or a limit cycle (both the number of predators and the number of prey oscillate, reaching their maximum values at different times, but eventually repeating). When nonlinear terms are introduced into the model, the population of each species can behave chaotically. You can think of each point that makes up such an attractor as the population of predators and prey in successive years. Since such complexity arises from these very simple models, it’s easy to understand why ecologists might have trouble predicting the fate of biological species!

Perhaps the best known chaotic two-dimensional map is the Hénon map (proposed by the French astronomer _Michel Hénon_ in 1976), whose equations are

$$
X_{n+1}=1+aX_n^2+bY_n
$$
$$
Y_{n+1}=X_n
$$

The quantities a and b are the control parameters, analogous to R in the logistic equation. Hénon used the values a = -1.4 and b = 0.3. The necessary nonlinearity is provided by the X 2 term in the first equation. The Hénon map is special because the net contraction of a set of initial points covering an area of the XY plane is constant with each iteration. The area occupied by the points is 30% of the area at the previous iteration (from the bYn  term). Other values of b can be used, but not all values produce chaotic solutions. Unlike the logistic map, the Hénon map is invertable; there is a unique value for Xn and Yn corresponding to each Xn+1 and Yn+1. You may have seen an alternate form of the Hénon equations in which the factor b appears instead in the second equation and the sign preceding the X2 term is negative. The result of repeated iteration of Equation 3A is shown in Figure 3-1.


3-1: The Henon map EWM?MPMMWMMMM F = 1.20 L = 0.60

The resulting graph is more than a line but less than a surface. What resembles a single line is a pair of lines, each of which is, in turn, another pair of lines, and so forth to however close you look or whatever magnification you choose. This selfsimilarity is a common characteristic of a class of objects that are called fractals.

Fractals are to chaos what geometry is to algebra—the visual expression of the mathematical idea. Approaching an understanding of chaos through such visual means is appealing to those with an aversion to conventional mathematics. The Euclidean geometry we learned in high school originated with the ancient Greeks and was developed more fully by the French mathematician Descartes and others in the 1600s. It deals with simple shapes such as lines, circles, and spheres. Euclidean geometry is now being augmented by fractal geometry, whose father and champion is the contemporary mathematician, Benoit Mandelbrot. Fractals appeared in art, such as in the drawings of the Dutch artist Maurits C. Escher, before they were widely appreciated by mathematicians and scientists.

Some fractals are exactly self-similar, which means that they look the same no matter how much you magnify them. Others, such as most of the ones in this book, only have regions that are self-similar. There is no part of the Hénon map where you can zoom in and find a miniature replica of the entire map. Other fractals are only statistically self-similar, which means that a magnified portion of the object has the same amount of detail as the whole, but it is not an exact replica of it. Nearly all strange attractors are fractals, but not all fractals arise from strange attractors.

The Hénon map produces an object with a fractal dimension that is a fraction intermediate between one and two. The fractal dimension is a useful quantity for characterizing strange attractors. Isolated points have dimension zero, line segments have dimension one, surfaces have dimension two, and solids have dimension three. Strange attractors generally have noninteger dimensions.

Some authors make a distinction between strange attractors, which have non-interger dimension, and chaotic attractors, which exhibit sensitivity to initial conditions.

Since the Hénon map has X 2 as its highest-order term, it is a quadratic map. The most general two-dimensional iterated quadratic map is

$$
X_{n+1}=a_1+a_2X_n+a_3X_n^2+a_4X_nY_n+a_5Y_n+a_6Y_n^2
$$
$$
Y_{N+1}=a_7+a_8X_n+a_9X_n^2+a_{10}X_nY_n+a_{11}Y_n+a_{12}Y_n^2
$$

The two equations in Equation 3B have 12 coefficients. For the Hénon map, $a_1 = 1$, $a_3 = -1.4$, $a_5 = 0.3$, $a_8 = 1$, and the other coefficients are zero. If we use the initial letter E to represent two-dimensional quadratic maps, the code for the Hénon map according to Table 2-1 is EWM?MPM2WM4, where we have introduced the shorthand M2 for MM and M4 for MMMM.

Values of a in the range of -1.2 to 1.2 are sufficient to produce an enormous variety of strange attractors. With increments of 0.1, there are 2512 or about 6 x 1016 different cases, of which approximately 1.6% or about 1015 are chaotic. Viewing them all at a rate of one per second would require over 30 million years! Stated differently, if each one were printed on an 81/2-by-11-inch sheet of paper, the collection would cover nearly the entire land mass of Earth.

Note that not all the cases are strictly distinct. For example, if you replace X
with Y and Y with -X in Equation 3B, you produce an attractor rotated 90 degrees counterclockwise from the original. When you do this, be sure to change Xn+1 and Yn+1 as well as Xn and Yn. Thus the code EM4CMWJM3? produces a rotated version of the Hénon map. In the same fashion, you can rotate an attractor through 180 degrees by replacing X with -X and Y with -Y and through 270 degrees by replacing  X with -Y and Y with X. Perhaps it’s easier just to rotate your computer monitor!

Besides rotations, there are cases that correspond to reflections. When viewed in a mirror, the attractors have left and right reversed, but up and down remain the same. A transformation in which X is replaced with -X accomplishes this. Thus the code for a reflected Hénon map is ECM[MJM2CM4. In addition, the reflections can be rotated. Thus there are at least eight so-called degenerate states  for each attractor, corresponding to rotations and reflections. Such symmetries and degeneracies play an important role in science; they often reduce the amount of work we have to do and provide relations between phenomena that initially
appear different.

Additional degenerate cases correspond to scale changes. For example, if you replace X by mX and Y by nY with m = n, the attractor remains the same except it is reduced in size by a factor of m. Some of the coefficients are likely to be outside the allowed range, however. The Hénon map with m = n = 2 can be generated with the code ERM1MPM2WM4. With m not equal to n, the horizontal and vertical dimensions are scaled differently, but since the computer rescales the attractor to fit the screen, the visual result is the same.

These degeneracies show that there are many ways to code a particular attractor. Although this is true, there are so many different possible combinations of coefficients that it is very unlikely that two degenerate cases will be found spontaneously. Thus the examples displayed in this chapter represent but a tiny fraction of the possibilities, and you will be generating many other cases, almost none of which have been seen before.

## The Butterfly Effect Revisited 

Two-dimensional chaotic iterated maps also exhibit sensitivity to initial conditions, but the situation is more complicated than for one-dimensional maps. Imagine a collection of initial conditions filling a small circular region of the XY plane.

After one iteration, the points have moved to a new position in the plane, but they now occupy an elongated region called an ellipse. The circle has contracted in one direction and expanded in the other. With each iteration, the ellipse gets longer and narrower, eventually stretching out into a long filament. The orientation of the filament also changes with each iteration, and it wraps up like a ball of taffy.

Thus two-dimensional chaotic maps have not a single Lyapunov exponent but two—a positive one corresponding to the direction of expansion, and a negative one corresponding to the direction of contraction. The signature of chaos is that at least one of the Lyapunov exponents is positive. Furthermore, the magnitude of the negative exponent has to be greater than the positive one so that initial conditions scattered throughout the basin of attraction contract onto an attractor that occupies a negligible portion of the plane. The area of the ellipse continually decreases even as it stretches to an infinite length.

There is a proper way to calculate both of the Lyapunov exponents. For the mathematically inclined, the procedure involves summing the logarithms of the eigenvalues of the Jacobian matrix of the linearized transformation with occasional Gram-Schmidt reorthonormalization. This method is slightly complicated, so we will instead devise a simpler procedure sufficient for determining the largest Lyapunov exponent, which is all we need in order to test for chaos. 

Suppose we take two arbitrary but nearby initial conditions. The first few iterations of the map may cause the points to get closer together or farther apart, depending on the initial orientation of the two points. Eventually, the points will come arbitrarily close in the direction of the contraction, but they will continue to separate in the direction of the expansion. Thus if we wait long enough, the rate of separation will be governed only by the largest Lyapunov exponent. Fortunately, this usually takes just a few iterations. 

However, because the separation grows exponentially for a chaotic system, the points quickly become too far apart for an accurate estimate of the exponent. This problem can be remedied if, after each iteration, the points are moved back to their original separation along the direction of the new separation. The Lyapunov exponent is then determined by the average of the distance they must be moved for each iteration to maintain a constant small separation. If the two solutions are separated by a distance dnafter the nth iteration, and the separation after the next iteration is $d_{n+1}$, the Lyapunov exponent is determined from

$$
L = \Sigma\frac{ log_2(\frac{d_{n+1}}{d_n})}{N}
$$
where the sum is taken over all iterations from n = 0 to n = N-1. After each iteration, the value of one of the iterates is changed to make dn+1 = dn. For the cases here, dn equals 10-6. This procedure also allows us to deal with maps of three and even higher dimensions in which there are more than two Lyapunov exponents.

## Searching the Plane 

We now have all the tools in hand to conduct a computer search for attractors in two dimensions. The procedure is the same as for one-dimensional maps, except the Lyapunov exponent calculation is done differently and the X and Y variables are plotted as a point in the plane after each iteration. PROG06 shows the changes needed to accomplish such a search.

1000 REM TWO-D MAP SEARCH
1060 OMAX% = 2 'Maximum order of polynomial
1070 D% = 2 'Dimension of system
1100 SND% = 0 'Turn sound off
1520 Y = .05
1550 XE = X + .000001: YE = Y
1590 XMIN = 1000000!: XMAX = -XMIN: YMIN = XMIN: YMAX = XMAX
1720 XNEW = A(1) + X * (A(2) + A(3) * X + A(4) * Y)
1730 XNEW = XNEW + Y * (A(5) + A(6) * Y)
1830 YNEW = A(7) + X * (A(8) + A(9) * X + A(10) * Y)
1930 YNEW = YNEW + Y * (A(11) + A(12) * Y)
2140 IF Y < YMIN THEN YMIN = Y
2150 IF Y > YMAX THEN YMAX = Y
2240 IF D% = 1 THEN XP = XS(I%): YP = XNEW ELSE XP = X: YP = Y
2250 IF N < 1000 OR XP <= XL OR XP >= XH OR YP <= YL OR YP >= YH THEN GOTO 2320
2300 PSET (XP, YP) 'Plot point on screen
2410 IF ABS(XNEW) + ABS(YNEW) > 1000000! THEN T% = 2 'Unbounded
2470 IF ABS(XNEW - X) + ABS(YNEW - Y) < .000001 THEN T% = 2
2520 Y = YNEW
2660 CODE$ = CHR$(59 + 4 * D% + O%)
2680 M% = 1: FOR I% = 1 TO D%: M% = M% * (O% + I%): NEXT I%
2910 XSAVE = XNEW: YSAVE = YNEW: X = XE: Y = YE: N = N - 1
2930 GOSUB 1700 'Reiterate equations
2940 DLX = XNEW - XSAVE: DLY = YNEW - YSAVE
2960 DL2 = DLX * DLX + DLY * DLY
2970 IF CSNG(DL2) <= 0 THEN GOTO 3070 'Don't divide by zero
2980 DF = 1000000000000# * DL2
2990 RS = 1 / SQR(DF)
3000 XE = XSAVE + RS * (XNEW - XSAVE): YE = YSAVE + RS * (YNEW - YSAVE)
3020 XNEW = XSAVE: YNEW = YSAVE
3030 IF DF > 0 THEN LSUM = LSUM + LOG(DF): NL = NL + 1
3040 L = .721347 * LSUM / NL
3110 IF D% = 1 THEN YMIN = XMIN: YMAX = XMAX


This program produces an incredible variety of interesting patterns, a small selection of which is shown in Figures 3-2 through 3-17. Admire the beauty and variety of these figures, and then make some of you own by running the program. If your computer has a printer, use the Print Screen key to print any that you find especially appealing.


Figure 3-2: EAGHNFODUMJCP F 1 = 1.36 L = 0.27 

Figure 3-3: EBCQAFMFVPXKQ F = 1.31 L = 0.13

Figure 3-4: EDSYVECIMGQNV F = 1.42 L = 0.03

Figure 3-5: EELXAMPXMPQOBT F = 1.55 L = 0.27

Figure 3-6: EEYYMKTUMXUVC F = 1.54 L = 0.08

Figure 3.7: EJTTSMBOGLLQF F = 1.37 L = 0.23

Figure 3.8: ENNMJRCTVVTYG F = 1.07 L = 0.01

Figure 3.9: EOVGFJKDHSAJU F = 1.38 L = 0.24

Figure 3.10: EQKOCSIDVTPGY F = 1.60 L = 0.34

Figure 3.11: EQLOIARXYGHAJ F = 1.47, L = 0.06 

Figure 3.12: ETJUBWEDNRORR F = 1.42, L = 0.16

Figure 3.13: ETSILUNDQSIFA F = 1.45, L = 0.17

Figure 3.14: EUEBJLCDISIIQ F = 1.25, L = 0.24

Figure 3.15: EVDOTLRBKTJD F = 1.54, L = 0.04 

Figure 3.16: EWLKPSMOGIGS F = 1.30, L = 0.02 

Figure 3.17: EZPMSGCMFRENG F = 1.67, L = 0.29

If you are an experienced programmer, you might consider writing a screensaver program based on PROG06. Such a terminate-and-stay-resident (TSR) program is run once when the computer is turned on and leaves a portion of itself in memory, constantly monitoring keyboard and mouse activity. When there is no user activity for, say, five minutes, it blanks the screen and begins displaying a succession of unique strange attractors to prevent screen burn-in. The original screen is restored whenever a key is pressed or the mouse is moved. PowerBASIC version 3.0 allows you to do this easily by inserting the program between POPUP statements.

## The Fractal Dimension 
	The previous figures differ considerably in how densely they fill the plane. Some are very thin, others are thick. A good contrast is provided by Figures 3-16 and 3-17. Figure 3-16 resembles a piece of string that has been laid down in a complicated shape on the page, whereas Figure 3-17 looks like a twisted piece of paper with many holes in it. Thus the object in Figure 3-16 has a fractal dimension close to 1, and the object in Figure 3-17 has a fractal dimension closer to 2.
	It is possible to be more explicit and to calculate the fractal dimension exactly. Consider two simple cases, one in which successive iterates lie uniformly along a straight line that goes diagonally across the page, and the other in which successive iterates gradually fill the entire plane, as if they were grains of pepper sprinkled on the paper from a great height. The first case has dimension 1, and the second has dimension 2. How would we calculate the dimension, given the X and Y coordinates of an arbitrary collection of such points?
	One method is to draw a small circle somewhere on the plane that surrounds at least one of the points. We then draw a second circle with the same center but with twice the radius. Now we count the number of points inside each circle. Let’s say the smaller circle encloses N1 points and the larger circle encloses N2 points. Obviously N2 is greater than or equal to N1 because all the points inside the inner circle are also inside the outer circle.
	If the points are widely separated, then N2 equals N1. If the points are part of a straight line, the larger circle on average encloses twice as many points as the smaller circle, but if the points are part of a plane, the larger circle on average encloses four times as many points as the smaller circle, because the area of a circle is proportional to the square of its radius. Thus for these simple cases the dimension is given by

	F = log2 (N2 / N1)          			(Equation 3D)

It is hardly surprising that if you do this operation for the cases shown in the figures, the quantity F is neither 0 nor 1 nor 2 but rather a fraction.
	With real data, a number of practical considerations determine the accuracy of the result and the amount of computation required to obtain it:

1. Is a circle the best shape, or would a square, rectangle, triangle, or some other shape be better?
2. How large should the circle be?
3. Is doubling the size of the circle optimal, or would some other factor be better?
4. Where should the circles be placed, and how many circles are required to obtain a representative average?
5. How many points are needed to produce a reliable fractal dimension?

Let’s address each of these questions in turn.
	There is nothing special about circles. A rectangle, triangle, or any other two-dimensional figure would suffice, because the area scales as the square of the linear dimension in each case. However, a circle is convenient because it is easy to tell whether a given point is in its interior by comparing the radius of the circle with the distance of the point from its center.
	The optimum size of the circle represents a compromise. Ideally, the circles should be invisibly small, because the dimension is defined in the limit of infinite resolution. However, if the circles are too small, they contain too few points to produce a statistically meaningful result, unless an unreasonably large number of iterations is performed. We somewhat arbitrarily use circles with a radius equal to about 2% of the diagonal of the smallest rectangle that contains the attractor.
	Similarly, doubling the radius of the circle is arbitrary. Small values degrade the statistics, and large values miss too much of the fine-scale structure. We will use a value of ten, with the smaller circle about 0.6% the size of the attractor and the larger circle about 6% the size of the attractor. Thus in Equation 3D we will use logarithms of base 10 (log10) instead of base 2 (log2).
	Ideally, the circles should be placed uniformly or randomly over the plane. However, if we were to do this, most of the circles would be empty, and a very long calculation would be required to obtain an accurate estimate of the dimension. Instead, we center the circles on the data points themselves. In this way the circles tend to enclose many points. However, it represents a different type of average because it weighs more heavily the portions of the attractor where the points are most dense. Technically, what we are calculating is called the correlation dimension, because it involves the number of other points that are correlated with each point in the data set. The correlation dimension is never greater than the fractal dimension, but it tends not to be much smaller either.
	The correlation dimension is only one of many ways to define the dimension of an attractor. The various methods differ in how the regions of the attractor are weighed in the average. It is probably the easiest method to implement, and it gives more reliable results than the fractal dimension when the dimension of the attractor is greater than about two. The fractal dimension is also called the capacity dimension, and it is closely related to the Hausdorff-Besicovitch dimension. Furthermore, the correlation dimension is probably a more meaningful measure of the strangeness of the attractor, because it includes information about its formation as well as its final appearance.
	The number of data points required to provide an accurate estimate of the dimension is a question still being debated in the scientific literature. Therefore, we will use a heuristic approach and continually update the dimension estimate with each iteration, giving you an opportunity to decide when it seems to have converged to a unique value. To do this, we must modify the procedure slightly. Rather than count the number of data points within a circle, which would require that the calculation run to conclusion with the coordinates of all the points saved, we use the equivalent method of determining the probability that two randomly chosen points are within a certain distance of one another. To do this, the distance of each new iterate from one of its randomly chosen predecessors is calculated. Now you see why we bothered to save the last 500 iterates! We exclude the most recent 20 points, because the iterates are likely to be abnormally highly correlated with their recent predecessors. Thus, with each iteration, we have only one additional calculation to do in which we compare the distance of the iterate to one of its randomly chosen predecessors and increment N1 and N2, as appropriate. PROG07 shows the changes needed to calculate and display the fractal dimension.

PROG07. Changes required in PROG06 to calculate and display the fractal dimension
1000 REM TWO-D MAP SEARCH (With Fractal Dimension)
1020 DIM XS(499), YS(499), A(504), V(99)

1580 P% = 0: LSUM = 0: N = 0: NL = 0: N1 = 0: N2 = 0
1620 TWOD% = 2 ^ D%

2210 XS(P%) = X: YS(P%) = Y

2440 GOSUB 3900                 'Calculate fractal dimension

3030    LSUM = LSUM + LOG(DF): NL = NL + 1
3060    IF N > 1000 AND N MOD 10 = 0 THEN LOCATE 1, 76: PRINT USING "##.##"; L;

3170 XL = XMIN - MX: XH = XMAX + MX: YL = YMIN - MY: YH = YMAX + 1.5 * MY
3190 YH = YH - .5 * MY
3400 LOCATE 1, 1: PRINT CODE$
3420 LOCATE 1, 63: PRINT "F =": LOCATE 1, 73: PRINT "L ="

3900 REM Calculate fractal dimension
3910 IF N < 1000 THEN GOTO 4010       'Wait for transient to settle
3920 IF N = 1000 THEN D2MAX = (XMAX - XMIN) ^ 2 + (YMAX - YMIN) ^ 2
3930 J% = (P% + 1 + INT(480 * RND)) MOD 500
3940 DX = XNEW - XS(J%): DY = YNEW - YS(J%)
3950 D2 = DX * DX + DY * DY
3960 IF D2 < .001 * TWOD% * D2MAX THEN N2 = N2 + 1
3970 IF D2 > .00001 * TWOD% * D2MAX THEN GOTO 4010
3980    N1 = N1 + 1
3990    F = .434294 * LOG(N2 / (N1 - .5))
4000    LOCATE 1, 66: PRINT USING "##.##"; F;
4010 RETURN

	At this point you might want to examine the fractal dimension of the various figures in this book as well as the dimension of those you create with PROG07. One thing you will notice is that the dimension of objects that resemble lines is often less than 1.0. One reason is that the points that make up the line are seldom uniformly distributed along its length. Remember that the correlation dimension is usually smaller than the fractal dimension. They are equal if the points are uniformly distributed over the attractor. The correlation dimension of a line consisting of a uniform distribution of points along its length would be exactly 1.0.
	Also note that the dimension of most attractors varies considerably from one part of the attractor to another. Figure 3-11 is a good example of one in which parts of the attractor resemble thin lines and other parts resemble filled-in planes. It obviously is simplistic to characterize such an object by a single average dimension.
	The dimension also depends on scale. It is properly defined in the limit where one zooms in very tightly on the attractor to observe its finest detail. However, a calculation in this limit would take forever because an infinite number of iterations would be required to collect enough points to reveal the detail. Figure 3-13 is an example of an attractor that is nearly one-dimensional on a large scale but closer to two-dimensional on a fine scale. Our calculation provides what might be called a visual dimension because it is taken on a scale close to what the eye can visually resolve. In any case, you should not ascribe undue significance to the calculated dimension.
	Also note that we are using the word “dimension” to mean several different things. The maps that we are looking at are two-dimensional because they have two variables, X and Y. However, the attractor has a smaller dimension. We say the attractor is embedded in a two-dimensional space or that the embedding dimension is 2. A point or a line can be embedded in a plane, but a ball cannot.
	An attractor usually fills a negligible portion of the space in which it is embedded. That’s why it’s called an attractor! Points initially distributed throughout the embedding space are drawn to the attractor after a number of iterations, and the remaining space is left empty. Thus the area of an attractor embedded in a two-dimensional space is zero, and the volume of an attractor embedded in a three-dimensional space is zero, and so forth.
	It is also interesting that the fractal dimension and the Lyapunov exponents are not entirely independent. It has been conjectured that the fractal dimension is related to the two Lyapunov exponents by

	F = 1 - L1 / L2 					(Equation 3E)

where L1 is the more positive of the two exponents and is the one we denote by L in the figures. If both Lyapunov exponents are known, Equation 3E can be used to define a dimension of the attractor, called the Lyapunov dimension. The Lyapunov dimension is also called the Kaplan-Yorke dimension after the scientists who proposed an extension of Equation 3E to higher dimensions.
	This relation is reasonable because, if the two exponents are equal but of opposite signs (L2 = - L1), the contraction in one direction is just offset by expansion in the other. A set of initial conditions spread out over a two-dimensional region thus maintains its area upon successive iteration. Such a mapping is said to be area-preserving, symplectic, or Hamiltonian, after the 19th-century Irish astronomer, William Rowan Hamilton. On the other hand, if the contraction is very rapid (L2 is large and negative), the initial conditions quickly collapse to a very elongated ellipse whose dimension is close to 1. Such a contraction is sometimes called filamentation.
	Armed with information about the fractal dimension, you can program the computer to be even more selective. For example, the visually appealing attractors tend to have fractal dimensions slightly greater than 1, and thus you could reject those with smaller dimensions or those with dimensions close to 2. We return to this intriguing possibility in Chapter 8.


## Higher-Order Disorder
	With one-dimensional maps, the attractors became more interesting when we considered terms higher than quadratic. It is straightforward to do the same with two-dimensional maps. For example, the most general equations for two-dimensional cubic maps are

	Xn+1 = a1 + a2Xn + a3Xn2 + a4Xn3 + a5Xn2Yn 
	+ a6XnYn  + a7XnYn2 + a8Yn + a9Yn2 + a10Yn3
	Yn+1 = a11 + a12Xn + a13Xn2 + a14Xn3 + a15Xn2Yn 
	+ a16XnYn + a17XnYn2 + a18Yn + a19Yn2 + a20Yn3 	(Equation 3F)

	Note that there are 20 coefficients, which vastly increases the number of possible cases. The fourth-order case would have 30 coefficients, and the fifth-order case would have 42 coefficients. If you prefer an equation, a two-dimensional map of order O has (O + 1)(O + 2) coefficients. We will code the cubic, quartic, and quintic cases with the letters F, G, and H, respectively.
	The changes that must be made to the program to generate attractors in two dimensions up to fifth order are given in PROG08.

PROG08. Changes required in PROG07 to generate attractors in two dimensions up to fifth order 
1000 REM TWO-D MAP SEARCH (Polynomials up to 5th Order)
1020 DIM XS(499), YS(499), A(504), V(99), XY(4), XN(4)
1060 OMAX% = 5                  'Maximum order of polynomial

1720 M% = 1: XY(1) = X: XY(2) = Y
1730 FOR I% = 1 TO D%
1740 XN(I%) = A(M%)
1750 M% = M% + 1
1760 FOR I1% = 1 TO D%
1770 XN(I%) = XN(I%) + A(M%) * XY(I1%)
1780 M% = M% + 1
1790 FOR I2% = I1% TO D%
1800 XN(I%) = XN(I%) + A(M%) * XY(I1%) * XY(I2%)
1810 M% = M% + 1
1820 IF O% = 2 THEN GOTO 1970
1830 FOR I3% = I2% TO D%
1840 XN(I%) = XN(I%) + A(M%) * XY(I1%) * XY(I2%) * XY(I3%)
1850 M% = M% + 1
1860 IF O% = 3 THEN GOTO 1960
1870 FOR I4% = I3% TO D%
1880 XN(I%) = XN(I%) + A(M%) * XY(I1%) * XY(I2%) * XY(I3%) * XY(I4%)
1890 M% = M% + 1
1900 IF O% = 4 THEN GOTO 1950
1910 FOR I5% = I4% TO D%
1920 XN(I%) = XN(I%) + A(M%) * XY(I1%) * XY(I2%) * XY(I3%) * XY(I4%) * XY(I5%)
1930 M% = M% + 1
1940 NEXT I5%
1950 NEXT I4%
1960 NEXT I3%
1970 NEXT I2%
1980 NEXT I1%
2000 NEXT I%
2010 M% = M% - 1: XNEW = XN(1): YNEW = XN(2)

	PROG08 could have been written more compactly, but it is done this way to simplify its extension to even higher dimensions. Examples of attractors produced by this program are shown in Figures 3-18 through 3-41.

Figure 3-18. Two-dimensional cubic map

Figure 3-19. Two-dimensional cubic map

Figure 3-20. Two-dimensional cubic map

Figure 3-21. Two-dimensional cubic map

Figure 3-22. Two-dimensional cubic map

Figure 3-23. Two-dimensional cubic map

Figure 3-24. Two-dimensional cubic map

Figure 3-25. Two-dimensional cubic map

Figure 3-26. Two-dimensional quartic map

Figure 3-27. Two-dimensional quartic map

Figure 3-28. Two-dimensional quartic map

Figure 3-29. Two-dimensional quartic map

Figure 3-30. Two-dimensional quartic map

Figure 3-31. Two-dimensional quartic map

Figure 3-32. Two-dimensional quartic map

Figure 3-33. Two-dimensional quartic map

Figure 3-34. Two-dimensional quintic map

Figure 3-35. Two-dimensional quintic map

Figure 3-36. Two-dimensional quintic map

Figure 3-37. Two-dimensional quintic map

Figure 3-38. Two-dimensional quintic map

Figure 3-39. Two-dimensional quintic map

Figure 3-40. Two-dimensional quintic map

Figure 3-41. Two-dimensional quintic map

	Perhaps this is a good point to pause and reiterate in what sense these objects are attractors. If you choose initial values of X and Y somewhere near the attractor, within its basin of attraction, and substitute these values into the equations that describe the attractor, the new values of X and Y represent a point in the plane that is closer to the attractor. After a number of iterations, the point works its way to the attractor, and thereafter it moves around on the attractor in some complicated manner, eventually visiting every part of the attractor. The next position can always be simply and accurately predicted from the current position, but the small, inevitable uncertainty in position continually increases so that a long-term prediction is impossible, except to say that the point is somewhere on the attractor. You can think of the attractor as the set of all possible long-term solutions of the equations that produced it.
	Besides the error in knowing perfectly the initial conditions, there are also computer round-off errors at each iteration. Given the extreme sensitivity to small errors, you may wonder whether any computer is capable of calculating correctly such a chaotic process. It is true that if the same chaotic equations are iterated on two computers using different precision or round-off methods, the sequence of iterates is almost certainly completely different after a few dozen iterations. However, the appearance of the attractor is probably the same. In such a case, we say that the solution is structurally stable or robust. Furthermore, according to the shadowing lemma, an appropriate small change in initial conditions produces a chaotic sequence that follows arbitrarily close to the computed one.
	Since computers always round the results of calculations to a finite number of digits (or more precisely, bits), a limited number of values is allowed. Thus successive iteration of a map always eventually repeats a previously obtained value, whereupon the solution reproduces exactly the same sequence of states as it did before. Strictly speaking, every such solution is periodic, and true chaos cannot be observed with a computer. However, with double-precision floating-point variables, which are normally 64 bits, there are 264 or about 1019 possible values. It can be shown that an average periodicity occurs after about the square root of this number of iterations, which is about 3 x 109. Until the number of iterations approaches this value, there is little cause to worry. For maps higher than one dimension, this problem is even less serious because all the variables have to reach a previously existing state at the same time.
	It is also interesting to realize that infinitely many periodic solutions are embedded in each attractor. These solutions are called periodic orbits. From wherever you start on the attractor, you eventually return to a point arbitrarily close to the starting point. This result is called the Poincaré recurrence theorem, after Jules-Henri Poincaré, a French mathematician who a hundred years ago portended the modern era of chaos. Thus by making only a small change in the starting point, it is possible, in principle, to return exactly to the starting point, which implies a periodic orbit with a period equal to the number of iterations required to return. Most of these orbits have very large periods, however.
	Every point on the attractor is arbitrarily close to such a periodic orbit, but the chance that a randomly chosen point on the attractor lies on such an orbit is infinitesimal. We say that the periodic orbits are dense on the attractor. These orbits, though infinite in number, constitute a Cantor set of measure zero. The periodic orbits are unstable in the sense that if you get just slightly off the orbit, you continue to get farther away with each iteration.
	The strange attractors exhibited in this book are examples of orbital fractals. They should be distinguished from escape-time fractals, which show the basin of attraction and typically display with color the number of iterations required for points outside the basin to escape beyond some predefined region. The Mandelbrot and Julia sets are perhaps the best-known escape-time fractals. Escape-time fractals require much longer computing times to develop but provide dazzling displays with exotic fine-scale structures.


## Strange Attractor Planets
	The previous figures have obvious beauty, but they generally lack symmetry. Nature mixes symmetry with disorder, and our sense of beauty has developed accordingly. The Earth viewed from outer space is beautiful in part because the irregular features of the clouds and continents are superimposed on a nearly perfect sphere.
	There are many ways to do the same with our attractors. Suppose, for example, X and Y are not the horizontal and vertical positions in a plane but rather the longitude and latitude on the surface of the Earth. The result is an object that might resemble a strange planet with swirling clouds, oceans, canals, craters, and other features.
	Note that mapping a plane onto a sphere is a nonlinear transformation. You can’t wrap a piece of paper around a globe without a large nonuniform stretching. That’s why Greenland looks larger than South America on most flat maps. When a sphere is projected onto a flat computer screen or onto the page of a book, it is stretched so as to magnify the central portion of the attractor and compress the edges.
	If  is the longitude (measured from zero at the right edge) and  is the latitude (measured from zero at the top), the X and Y coordinates of the projection of a sphere onto the screen are given by

	Xp = cos q sin f
	Yp = cos f						(Equation 3G)

	We get  from X by a scaling that keeps  in the range of  to  radians (180 degrees), because there is no need to plot points that lie on the back side of the planet. Similarly, we get  from Y by a scaling that keeps  in the range of  (at the North Pole) to  radians (at the South Pole). The program modifications required to accomplish this transformation are given in PROG09. This program allows you to toggle back and forth between the two types of projection by pressing the P key.

PROG09. Changes required in PROG08 to project attractor onto a sphere
1000 REM TWO-D MAP SEARCH (Projected onto a Sphere)
1110 PJT% = 1                   'Projection is spherical

2260    IF PJT% = 1 THEN GOSUB 4100     'Project onto a sphere

3200 XA = (XL + XH) / 2: YA = (YL + YH) / 2
3310 IF PJT% <> 1 THEN LINE (XL, YL)-(XH, YH), , B
3320 IF PJT% = 1 THEN CIRCLE (XA, YA), .36 * (XH - XL)
3330 TT = 3.1416 / (XMAX - XMIN): PT = 3.1416 / (YMAX - YMIN)

3750 IF Q$ = "P" THEN PJT% = (PJT% + 1) MOD 2: T% = 3: IF N > 999 THEN N = 999

4100 REM Project onto a sphere
4110 TH = TT * (XMAX - XP)
4120 PH = PT * (YMAX - YP)
4130 XP = XA + .36 * (XH - XL) * COS(TH) * SIN(PH)
4140 YP = YA + .5 * (YH - YL) * COS(PH)
4150 RETURN

	Figures 3-42 through 3-57 show some examples of two-dimensional attractors projected onto a sphere. Note that the features on the attractors tend to converge at the poles at the tops and bottoms of the figures. This convergence could be suppressed by using an area-preserving transformation that stretches the Y values near the poles by the same factor that the X values are compressed. The simplest way to produce this effect is to delete line 4140.

Figure 3-42. Two-dimensional quadratic map projected onto a sphere

Figure 3-43. Two-dimensional quadratic map projected onto a sphere

Figure 3-44. Two-dimensional quadratic map projected onto a sphere

Figure 3-45. Two-dimensional quadratic map projected onto a sphere

Figure 3-46. Two-dimensional cubic map projected onto a sphere

Figure 3-47. Two-dimensional cubic map projected onto a sphere

Figure 3-48. Two-dimensional cubic map projected onto a sphere

Figure 3-49. Two-dimensional cubic map projected onto a sphere

Figure 3-50. Two-dimensional quartic map projected onto a sphere

Figure 3-51. Two-dimensional quartic map projected onto a sphere

Figure 3-52. Two-dimensional quartic map projected onto a sphere

Figure 3-53. Two-dimensional quartic map projected onto a sphere

Figure 3-54. Two-dimensional quintic map projected onto a sphere

Figure 3-55. Two-dimensional quintic map projected onto a sphere

Figure 3-56. Two-dimensional quintic map projected onto a sphere

Figure 3-57. Two-dimensional quintic map projected onto a sphere

	If you are using PowerBASIC or its predecessor, Turbo BASIC, and VGA graphics, you will notice a slight incompatibility with the CIRCLE command that causes the size of the circle that surrounds the attractor to vary from case to case. In these dialects of BASIC, the radius of the circle in SCREEN modes 11 and 12 is specified in units of the screen height rather than its width. If you encounter this problem, try replacing .36 * (XH - XL) in line 3320 with .5 * (YH - YL).
	Planes and spheres are not the only two-dimensional surfaces onto which attractors can be projected. A cylinder is another possibility. The cylinder can be oriented with its axis either horizontal or vertical or tilted at some arbitrary angle. A torus is another possibility. You may be able to think of other more exotic surfaces onto which the attractors can be projected.

## Designer Plaids
	It is interesting that all the one-dimensional maps described in the previous chapter are included in the two-dimensional cases. One needs only to set the coefficients of the Y equation to zero. For example, a two-dimensional map equivalent to the logistic equation is given by the code EMu%M9. However, because Y doesn’t change with successive iterations, a graph of Y versus X is simply a straight, horizontal line.
	To display the logistic parabola, we need to replace X with the next iterate of X and Y with the second next iterate of X. Two successive iterations of a quadratic map requires a fourth-order equation. A code that accomplishes this is GMu%M13NHUIM10.
	There are other examples of two-dimensional maps that are really one-dimensional maps in disguise. Suppose Xn+1 depends only on Yn and Yn+1 depends only on Xn. Then Xn+2 depends only on Xn, and we have a one-dimensional map for X in which Y is merely an intermediate value of X. The most general fifth-order polynomial example of such a case is

	Xn+1 = a1 + a17Yn + a18Yn2 + a19Yn3 + a20Yn4 + a21Yn5
	Yn+1 = a22 + a23Xn + a24Xn2 + a25Xn3 + a26Xn4 + a27Xn5		(Equation 3H)

This case can be achieved by setting the remaining 30 coefficients to zero in PROG09 by adding the following line after line 2730:

2735    IF (I% > 1 AND I% < M% / 2 - O%) OR I% > M% / 2 + O% + 1 THEN MID$(CODE$, I% + 1, 1) = "M"

The result is to produce a 25th-order, one-dimensional polynomial map displayed in two dimensions.
	Figures 3-58 through 3-61 show sample attractors obtained in this way. Notice that they fill in rectangular regions resembling a plaid tartan, in sharp contrast to all the previous cases. These attractors are especially appropriate for projecting onto spheres because the features line up east-west along parallels and north-south along meridians. Figures 3-62 and 3-63 show some examples of plaid planetary attractors.

Figure 3-58. Two-dimensional quadratic plaid map

Figure 3-59. Two-dimensional cubic plaid map

Figure 3-60. Two-dimensional quartic plaid map

Figure 3-61. Two-dimensional quintic plaid map

Figure 3-62. Two-dimensional quadratic plaid map on a sphere

Figure 3-63. Two-dimensional quintic plaid map on a sphere

	You might want to try adding colors to emulate a decorative cloth pattern. One way to do this is to color the pixels according to the number of times they are visited by the orbit. This is easily done by changing line 2300 in the program to

2300    PSET (XP, YP), (POINT (XP, YP) + 1) MOD 16

which causes the color of the existing point at (XP, YP) to be tested and then plotted with the next color in the palette of 16 colors. In Chapter 4, we discuss other ways to produce colorful attractors.


## Strange Attractors that Don’t
	From the foregoing discussion, you might conclude that all chaotic equations produce strange attractors. Such is not the case. Under certain conditions, the successive iterates of an equation wanders chaotically throughout a region of the plane. There is no basin of attraction, and initial conditions near but outside the chaotic region are not drawn to the region but rather lie on closed curves. Although the chaotic region is not a strange attractor, it may have considerable beauty.
	For a chaotic solution not to attract, the area occupied by a cluster of nearby initial conditions must remain the same with successive iterations. The cluster generally contracts in one direction and expands in the other, but the contraction and expansion just cancel, producing a long, thin filament of constant area. A characteristic of such a case is that the two Lyapunov exponents are equal in magnitude but of opposite signs. Such a system is area-preserving. An important class of area-preserving systems are Hamiltonian systems with their corresponding symplectic maps.
	You might think that Hamiltonian systems are relatively rare in nature, because they require a special condition. However, there are many important examples of Hamiltonian chaos. They arise because there are quantities in nature such as energy and angular momentum that, in the absence of friction, remain accurately constant no matter how complicated the behavior of the system. We say these quantities are conserved or that they are constants of the motion. The motion of a planet orbiting a binary-star system or the motion of an electron near the null in a magnetic field exhibits Hamiltonian chaos. A more familiar example is the filamentation of milk when it is stirred into coffee, in which case the volume of the milk is conserved because liquids are nearly incompressible.
	With equations such as those we have been using with randomly chosen coefficients, the chance of inadvertently finding an area-preserving solution is essentially zero. However, by placing appropriate conditions on the coefficients, we can guarantee such solutions. The following is an example of an area-preserving, two-dimensional polynomial map:

	Xn+1 = a1 + a2Xn + a3Xn2 + a4Xn3 + a5Xn4 + a6Xn5 ± Yn
	Yn+1 = a22 ± Xn							(Equation 3I)

	This map is fifth order to provide seven arbitrary coefficients that ensure a large number of solutions. The coefficient labels are consistent with the general two-dimensional fifth-order map, in which 33 of the coefficients have been set to zero. The two terms preceded with ± have coefficients (a17 and a23) of either +1 or -1, and this feature guarantees an area-preserving solution. If the signs are the same (both plus or both minus), chaotic solutions are not found. Hamiltonian chaos can occur when the signs are opposite. The negative product of these two coefficients is the Jacobian of the map (J = -a17a23). The Jacobian is a measure of the net contraction, and it must equal 1.0 for a Hamiltonian system.
	Hamiltonian cases can be produced by adding the following lines to PROG09 after line 2730:

2735    IF I% > O% + 1 AND I% <> M% / 2 + 1 THEN MID$(CODE$, I% + 		 1, 1) = "M"
2736    MID$(CODE$, M% / 2 - O% + 2, 1) = "W": MID$(CODE$, M% / 2 + 	 3, 1) = "C"

	Sample chaotic symplectic maps are shown in Figures 3-64 through 3-71. Most of the cases resemble chains of islands in which each island contains a fixed point surrounded by closed contours that are not shown. These cases were produced using initial values of X = Y = 0.05. Other initial conditions would produce completely different pictures because there is no attractor.

Figure 3-64. Two-dimensional quintic symplectic map

Figure 3-65. Two-dimensional quintic symplectic map

Figure 3-66. Two-dimensional quintic symplectic map

Figure 3-67. Two-dimensional quintic symplectic map

Figure 3-68. Two-dimensional quintic symplectic map

Figure 3-69. Two-dimensional quintic symplectic map

Figure 3-70. Two-dimensional quintic symplectic map

Figure 3-71. Two-dimensional quintic symplectic map
These cases have a different look from non-symplectic strange attractors. The difference is even more pronounced if you watch while they develop on the computer screen. Whereas the regions of a strange attractor tend to be visited uniformly and apparently randomly, the symplectic maps develop much more slowly. The points often wander over a small region for tens of thousands of iterations, and then they suddenly begin to fill in a new distinct region that has never been visited before. Consequently, many more iterations are required to determine the stability and chaotic nature of the solution. You need to be patient while the computer calculates.

	The different time behavior of these cases raises an important issue. When you view any of the figures in this book, you are seeing a static object. However, it was produced by a dynamic process. Information about the sequence in which the points accumulated has been lost. This additional information is recovered when you watch the attractors develop on your computer screen. Most of the attractors fill in uniformly. Their contrast gets progressively greater, much like a photographic print being developed.
	However, the symplectic maps develop more slowly and in stages. If your computer has a color monitor, you might try exhibiting this sequence by plotting the points in color and changing the color every few thousand iterations. Some examples using this technique are shown in Section 7.5. If you try this for the non-symplectic attractors, the colors overlap and merge into a uniform gray, or you just see the most recent color. For the symplectic maps, beautiful color patterns can be produced. Otherwise, continue on to the next chapter, where various color techniques are discussed.


## A New Dimension in Sound
	With one-dimensional maps, we tried to make music by letting successive iterates control the pitch of the musical notes, all of which were of the same duration. The same procedure can be used with two-dimensional maps. However, we have a second variable at our disposal, so let’s use it to control the duration of each note. With actual music, it turns out that there are many more notes of short duration than of long duration. There are roughly twice as many half notes as whole notes, and twice as many quarter notes as half notes, and so forth. This remarkable result seems to hold for all types of music from different composers and cultures. It is evidence of hidden determinism in music.
	The program modification PROG10 uses the X value to control the pitch and the Y value to control the duration of the notes. For convenience, we assume that the longest note is a whole note and the shortest note is a sixteenth note. Dotted notes and rests are not allowed.
	PROG10 also adds to the program a menu screen that reminds you of the S command, which toggles the sound on and off, and the P command, which toggles the projection between planar and spherical. We also introduce an A command to initiate the search for attractors, a D command to toggle between one-dimensional and two-dimensional maps, an I command to let you input the code of an attractor that you know, and an X command to exit the program. Pressing any other key displays the menu screen.

PROG10. Changes required in PROG09 to produce chaotic music and provide a menu screen
1000 REM TWO-D MAP SEARCH (With Music and Menu Screen)
1100 SND% = 1                   'Turn sound on
1110 PJT% = 0                   'Projection is planar
1170 GOSUB 4200                 'Display menu screen
1180 IF Q$ = "X" THEN GOTO 1250 'Exit immediately on command

2450 IF QM% > 0 THEN GOTO 2490  'Skip tests when not in search mode

2640 IF QM% > 0 THEN GOTO 2730  'Not in search mode
2650    O% = 2 + INT((OMAX% - 1) * RND)
2660    CODE$ = CHR$(59 + 4 * D% + O%)
2680    GOSUB 4700              'Get value of M%

3530 IF D% > 1 THEN DUR = 2 ^ INT(.5 * (YH - YL) / (YNEW - 9 * YL / 8 + YH / 8))

3610 IF ASC(Q$) > 96 THEN Q$ = CHR$(ASC(Q$) - 32)   'Convert to upper case
3630 IF Q$ = "" OR INSTR("ADIPSX", Q$) = 0 THEN GOSUB 4200
3640 IF Q$ = "A" THEN T% = 1: QM% = 0
3680 IF Q$ = "D" THEN D% = 1 + (D% MOD 2): T% = 1
3730 IF Q$ = "I" THEN IF T% <> 1 THEN SCREEN 0: WIDTH 80: COLOR 15, 1: CLS : LINE INPUT "Code? "; CODE$: IF CODE$ = "" THEN Q$ = " ": CLS :  ELSE T% = 1: QM% = 1: GOSUB 4700
3790 IF Q$ = "X" THEN T% = 0

4200 REM Display menu screen
4210 SCREEN 0: WIDTH 80: COLOR 15, 1: CLS
4220 WHILE Q$ = "" OR INSTR("AIX", Q$) = 0
4230    LOCATE 1, 27: PRINT "STRANGE ATTRACTOR PROGRAM"
4260    PRINT : PRINT
4270    PRINT TAB(27); "A: Search for attractors"
4300    PRINT TAB(27); "D: System is"; STR$(D%); "-D polynomial 		 map"
4370    PRINT TAB(27); "I: Input code from keyboard"
4400    PRINT TAB(27); "P: Projection is ";
4410        IF PJT% = 0 THEN PRINT "planar   "
4420        IF PJT% = 1 THEN PRINT "spherical"
4540    PRINT TAB(27); "S: Sound is ";
4550        IF SND% = 0 THEN PRINT "off"
4560        IF SND% = 1 THEN PRINT "on "
4600    PRINT TAB(27); "X: Exit program"
4610    Q$ = INKEY$
4620    IF Q$ <> "" THEN GOSUB 3600     'Respond to user command
4630 WEND
4640 RETURN

4700 REM Get dimension and order
4710 D% = 1 + INT((ASC(LEFT$(CODE$, 1)) - 65) / 4)
4740 O% = 2 + (ASC(LEFT$(CODE$, 1)) - 65) MOD 4
4750 M% = 1: FOR I% = 1 TO D%: M% = M% * (O% + I%): NEXT I%
4770 IF LEN(CODE$) = M% + 1 OR QM% <> 1 THEN GOTO 4810
4780    BEEP        'Illegal code warning
4790    WHILE LEN(CODE$) < M% + 1: CODE$ = CODE$ + "M": WEND
4800    IF LEN(CODE$) > M% + 1 THEN CODE$ = LEFT$(CODE$, M% + 1)
4810 RETURN

	As you listen to the music produced by the various attractors, you may discover relations between the quality of the music and the appearance of the attractor. The cases that seem most musical tend to have certain visual characteristics, which are left for you to discover. Do attractors that appeal to the eye also appeal to the ear?
	After you have generated some music of your own, you may want to try some of the cases in Table 3-1 using the I command to input them to the program. These cases have been selected for their musical quality and are limited to quadratic maps to simplify typing their codes. An interesting study would be to accumulate your own longer list of musical attractors and to see if they preferentially have certain fractal dimensions and Lyapunov exponents. If so, then it should be possible to program the computer to be a music critic as well as an art critic.

Table 3-1. List of some musical attractors and their characteristics
Code	F	L	Code	F	L
EDFLQJGDGMSJV 	1.17 	0.35	EPLKQNGALTVDD 	1.03 	0.20
EGITIKLJNSKAT 	1.19 	0.04	EQVHVRXREMJED 	1.50 	0.19
EHXJCQMYLONDK 	0.95 	0.12	ERKKCUNHERKAV 	1.51 	0.47
EJETCOHRSIQFN 	1.56 	0.25	ESHKBEWJFUOPJ 	1.43 	0.39
EKLVEVAOSGYJX 	1.12 	0.20	ETFJJNMKESAFX 	0.97 	0.30
ELLNJNEAMPLDX 	1.11 	0.64	EUFLXKIETROOO 	0.90 	0.40
ENIDATWFTPOSL 	1.62 	0.26	EVHEQLLDMMBFP 	1.47 	0.49
EOKYEVMDXXJUP 	0.84 	0.22	EXJNXAIFANNEN 	1.60 	0.17

	After listening to the enormous variety of musical sequences that can be generated by this technique, you might wonder whether your favorite musical composition could be compressed into a short code and generated using iterated maps. After all, even the simple cases in Table 3-1 are chosen from among about 6 x 1016 different codes, and each code corresponds to a different piece of music.
	However, a typical musical piece might have hundreds or thousands of notes, each of which can represent dozens of pitches and many durations. Thus we can be fairly confident using the principles of information theory that such extreme compression is unlikely, unless music has considerably more structure than is apparent. However, if you only want to generate a short tune with a few notes, there might well be a way to do so using this technique. If you are mathematically inclined, take it as a challenge to find a way to do this.
	The generation of computer music using chaotic iterated maps is a promising technique still in its infancy. You may want to incorporate more sophisticated musical rules into the program to generate music that is much more pleasing than what results from this simple procedure. Furthermore, an interesting project would be to turn the process around and see if music written by humans resembles a strange attractor, and if so, to measure its fractal dimension and Lyapunov exponent. Perhaps music of different types or by different composers would have different values of these quantities.
