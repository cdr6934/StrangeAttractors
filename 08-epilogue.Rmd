Chapter 8
Epilogue
It would be an injustice to leave you with the impression that the main use of the ideas in this book is to make pretty pictures. This final chapter describes some of the scientific applications of the method used to generate this large collection of strange attractors. It also suggests some additional explorations you might want to undertake as an extension of both the scientific and artistic aspects of the work described in this book.


## How Common is Chaos?
	For hundreds of years, scientists have used equations like those in the previous chapters to describe nature. It is remarkable that almost no one recognized the chaotic solutions to those equations until the last few decades of the 20th century. Now researchers in many disciplines are beginning to see chaos under every rock. It is reasonable to wonder whether chaos is the rule or the exception.
	Suppose we had a system of equations of sufficient complexity and with sufficiently many coefficients that it could be used to model most natural processes. We could then attempt to quantify the occurrence of chaos in these equations and draw an inference about the occurrence of chaos in nature. The equations in the previous chapters, especially those involving polynomials of high dimension and high order, might approximate such a system.
	As a simple but very unrealistic example, suppose that all of nature could be modeled by the logistic equation (Equation 1C). This equation has a single parameter R that controls the character of the solution. If R is greater than 4 or less than -2, the solutions are unbounded, which means that this equation cannot model a physical process under those conditions. Essentially all physical processes are bounded, except perhaps the trajectory of a spacecraft launched with sufficient velocity to escape the galaxy. In the physically realistic range of R, there is a band of chaos between about 3.5 and 4, as shown in Figure 1-2 and another identical band between about -1.5 and -2. Careful analysis shows that chaos occurs over about 13% of the range of R from -2 to 4.
	Since the logistic equation is too simple a model for almost everything, we should examine more complicated models. The Hénon map (Equation 3A) is a two-dimensional generalization of the logistic map. It has two control parameters, which normally are a = -1.4 and b = 0.3. With b = 0, the Hénon map reduces to the logistic map.
	As with the logistic map, the Hénon map has unbounded solutions, chaotic solutions, and bounded nonchaotic solutions, depending on the values of a and b. The bounded nonchaotic solutions may be either fixed points or  periodic limit cycles. Figure 8-1 shows a region of the ab plane with the four classes of solutions indicated by different shades of gray. The bounded solutions constitute an island in the ab plane. On the northwest shore of this island is a chaotic beach, which occupies about 6% of the area of the island. The chaotic beach has many small embedded periodic ponds. The boundary between the chaotic and the periodic regions is itself a fractal.

Figure 8-1. Regions of solutions for the Hénon map in the ab plane

	The logistic map is chaotic over 13% of its bounded range, and the Hénon map is chaotic over 6% of its bounded range. This result is counterintuitive because it suggests that more complicated (two-dimensional) systems are in some sense less chaotic than simpler (one-dimensional) systems. Is this a general result, or is it peculiar to these two maps? One way to decide is to examine a wider selection of equations, such as the ones used to produce the attractors exhibited throughout this book.
	In collecting attractors, we have been discarding interesting information—the number of bounded nonchaotic solutions for each chaotic case that the program finds. Discarding data is offensive to scientists, since experiments are often performed with great effort and at considerable expense. The annals of science are ripe with examples of important discoveries that could have been made sooner or by others if only the right data had been recorded and analyzed.
	Table 8-1 shows the results from 30,000 chaotic cases (1000 for each of the 30 types) as identified by the program. This table includes over 400 million cases, of which about 1 million are bounded. Of all the bounded solutions, 2.8% were chaotic according to the criterion described in Section 2.4. The polynomial maps all exhibit a similar occurrence of chaotic solutions. The same is true of ordinary differential equations (ODEs), but the percentage is smaller. The reason for this behavior is not understood.

Table 8-1. Summary of data from 30,000 chaotic cases
Code	D	O	Type	Chaotic	Average F	Average L
A	1	2	Map	3.34%	0.81±0.15	0.53±0.42
B	1	3	Map	5.09%	0.80±0.14	0.50±0.40
C	1	4	Map	8.09%	0.82±0.12	0.52±0.20
D	1	5	Map	7.94%	0.80±0.14	0.51±0.21
E	2	2	Map	7.58%	1.20±0.32	0.27±0.16
F	2	3	Map	7.08%	1.19±0.33	0.27±0.15
G	2	4	Map	6.40%	1.16±0.32	0.27±0.15
H	2	5	Map	5.79%	1.19±0.30	0.28±0.16
I	3	2	Map	6.68%	1.50±0.40	0.16±0.10
J	3	3	Map	5.89%	1.45±0.39	0.15±0.09
K	3	4	Map	5.08%	1.45±0.41	0.15±0.09
L	3	5	Map	4.68%	1.43±0.39	0.14±0.09
M	4	2	Map	4.99%	1.64±0.47	0.10±0.06
N	4	3	Map	4.78%	1.59±0.46	0.09±0.06
O	4	4	Map	5.32%	1.61±0.45	0.09±0.06
P	4	5	Map	5.04%	1.62±0.47	0.10±0.06
Q	3	2	ODE	0.55%	1.28±0.41	0.21±0.33
R	3	3	ODE	1.33%	1.31±0.40	0.73±0.76
S	3	4	ODE	1.23%	1.35±0.40	1.05±0.98
T	3	5	ODE	1.63%	1.38±0.41	1.23±1.16
U	4	2	ODE	1.34%	1.43±0.43	0.16±0.23
V	4	3	ODE	1.84%	1.43±0.43	0.40±0.48
W	4	4	ODE	1.84%	1.46±0.45	0.54±0.62
X	4	5	ODE	1.96%	1.44±0.44	0.66±0.76
Y	4	Special	16.28%	1.37±0.56	0.26±0.26
Z	4	Special	23.19%	1.03±0.44	0.28±0.44
[	4	Special	16.00%	0.63±0.65	0.42±0.23
\	4	Special	1.61%	1.10±0.28	0.16±0.10
]	4	Special	19.80%	1.02±0.16	0.06±0.04
^	4	Special	1.91%	1.80±0.49	0.39±1.03

	These results should not be taken too literally because the coefficients have been limited to the range -1.2 to 1.2, the ODEs have not been solved very accurately, and many cases are ambiguous. Chaotic solutions tend to occur at large values of the coefficients where most of the solutions are unbounded. A more careful evaluation, which corrects these difficulties and includes about 35,000 strange attractors but limited to fewer types, shows that the probability that a bounded solution is chaotic for an iterated polynomial map of dimension D and order O is given approximately by

	P = 0.349 D-1.69 O-0.28          			(Equation 8A)

Similarly, the probability that a bounded solution is chaotic for a polynomial ODE of dimension D and order O is given approximately by

	P = 0.0003 D2 O0.5          			(Equation 8B)

Maps appear to become less chaotic as they become more complicated (larger D and O), whereas ODEs become more chaotic.
	To assess how common chaos is in nature, we must address the more complicated and subjective issue of whether the equations we have examined are a representative sample of the equations that describe natural processes. Furthermore, we cannot assume a priori that nature selects the coefficients of the equations uniformly over the bounded region of control space. It is possible that other constraints mitigate either against or in favor of chaotic behavior.
	Another interesting question is how the fractal dimension and the Lyapunov exponent vary with the dimension and order of the system. Table 8-1 includes the average values of these quantities plus or minus (±) the standard deviation for each type of chaotic system. For polynomial maps and ODEs, the fractal dimension varies approximately as the square root of the system dimension. For polynomial maps, the Lyapunov exponent varies inversely with the system dimension. For polynomial ODEs, the Lyapunov exponent increases with the system dimension. The Lyapunov exponent appears to be independent of order for maps, but there is a tendency for the Lyapunov exponent of ODEs to increase with order.
	These results are summarized in Figures 8-2 and 8-3. Figure 8-2 shows the relative probability that a strange attractor from a polynomial map or ODE will have a fractal dimension F plotted versus F/D0.5. The curve is sharply peaked at a value of about 0.8. Almost no attractors have a fractal dimension greater than about 1.3D0.5. The Lorenz and Rössler attractors (with fractal dimensions slightly above 2.0 in a three-dimensional space) are close to this maximum value. Figure 8-3 shows the relative probability that a strange attractor from a polynomial map will have a Lyapunov exponent L plotted versus LD. This curve shows a much broader peak at about 0.5. These results hold when the calculations are done more carefully. The reason for this behavior is not understood, but it is potentially important because it gives an indication of the complexity of the system of equations responsible for a strange attractor that one observes in nature.

Figure 8-2. Probability distribution of fractal dimension

Figure 8-3. Probability distribution of Lyapunov exponent

	The similarity of the fractal dimension for attractors produced by polynomials of the same dimensionality raises the concern that they might in some sense all be the same attractor, viewed from different angles and distorted in various ways. There may be a simple mapping that converts one attractor into the others. In such a case, a statistical analysis of the collection would be misleading and meaningless. However, since the Lyapunov exponents are spread over a broad range, it seems likely that the attractors are distinct. In any case, they are visually very different, and thus the technique has artistic if not scientific value.
	It is interesting to ask whether the above results are peculiar to polynomials. Table 8-1 includes data for the special functions that were described in Chapter 7. Some of these cases tend to be more chaotic than the polynomials, but the differences are not enormous. Thus is would appear, insofar as nature can be represented by systems of equations of the type described in this book, that chaos is not the most common behavior, but neither is it particularly rare.


## But Is It Art?
	A very different question is whether pictures generated by solving deterministic equations with a computer can legitimately qualify as art. Some people would say that if it was done by a computer without human intervention, it cannot be art. On the other hand, humans chose the equations, built and programmed the computer, decided how the solution would be displayed, and selected from the large number of cases that the computer generated. In this view, the computer is just another tool in the hands of the artist.
	At the core of the issue is what we mean by art. There are at least two, not necessarily mutually incompatible, views. One is that art is the expression of ideas and emotions—a form of communication between the artist and the observer. The other emphasizes formal design, in which the viewer admires the skill with which the artist manipulated the materials, without reading any particular meaning into it.
	Strange attractors qualify by either definition. They are expressions of ideas embodied in the equations, whether it be the dynamics of population growth or a swinging pendulum. These ideas are often abstract and are most apparent to the trained mathematician or scientist, but anyone can see in the patterns the surreal images of plants, animals, clouds, and swirling fluids. The appearance of such familiar images in the solutions of mathematical equations is probably more than coincidental.
	Strange attractors also necessarily embody concepts of design. The interplay of determinism and unpredictability ensures that they are neither formless nor excessively repetitious. Furthermore, the skills of an artisan (if not an artist) are required to translate the abstract equations into aesthetically desirable visual forms. These skills are different from (but not inferior to) those possessed by more conventional artists. Renaissance artists, such as Leonardo da Vinci, were often also scientists. We may now be entering a new Renaissance in which art and science are again being drawn together through the visual images produced by computers.
	Some artists view art as a creative process whose primary goal is to provide the artist with a sense of satisfaction. The resulting work is merely an inevitable by-product. This view seems especially appropriate for the production of strange attractors, where the programmer’s satisfaction is derived from causing the computer to generate the patterns, even if they are never seen by anyone else. Indeed, the computer offers the ideal medium for such conceptual artists, since there need be no material product whatsoever.
	Note that visual art need not be beautiful to be good, just as a play need not be humorous. It may be intellectually or emotionally satisfying, or even disturbing. It should capture and hold the interest of the viewer, however. The span of the viewer’s attention is one measure of its quality. Art may mix the familiar and the unfamiliar to produce both comfort and dissonance. Furthermore, beauty is at least partially in the eye of the beholder, although recent research indicates that there are absolute universal measures of beauty that form very early in life and may even be genetic.


## Can Computers Critique Art?
	The idea that a computer can make aesthetic judgments seems absurd and even offensive to many people. Yet the program developed in this book is already doing this to some degree. For every object (strange attractor) that it identifies, it has discarded many dozens as being uninteresting (nonchaotic). Perhaps the computer could be programmed to be even more discriminating and to select those strange attractors that are likely to appeal to humans. To the extent that aesthetic judgment involves objective as well as subjective criteria, such a proposition is not unreasonable.
	A computer lacks emotion, but it can be taught in much the same way that people can be taught. With the help of a human to point out which attractors are visually interesting, the computer can correlate human opinion with various quantitative measures of the attractor. It can then test each new case and assign a probability that it would appeal to a human.
	One of the reasons we have been calculating and saving the fractal dimension and Lyapunov exponent for each strange attractor is in anticipation of developing such criteria. You can think of the dimension as a measure of the strangeness of an attractor and the Lyapunov exponent as a measure of its chaoticity. These are just two of infinitely many independent quantities we can use to describe each attractor. If we find encouragement from them, it suggests that more can be done.
	The first step is to search for a relation between the aesthetic quality and the fractal dimension or Lyapunov exponent. For this purpose, 7500 strange attractors from two-dimensional quadratic maps were evaluated by the author and seven volunteers, including two graduate art students, a former art history major, three physics graduate students, and a former mathematics major. All evaluators were born and raised in the United States. The evaluations were done by choosing attractors randomly and displaying them sequentially on the computer screen without any indication of the quantities that characterize them. The volunteers were asked to evaluate each case on a scale of one to five according to its aesthetic appeal. It only took a few seconds for each evaluation.
	Figure 8-4 displays a summary of all the evaluations as a function of fractal dimension (F) and Lyapunov exponent (L), using a gray scale in which the darker regions are the most highly rated. The cases examined by particular individuals show a similar trend. All evaluators tended to prefer attractors with dimensions between about 1.1 and 1.5 and Lyapunov exponents between zero and about 0.3. Some of the most interesting cases have Lyapunov exponents below about 0.1. You saw many such examples earlier in this book.

Figure 8-4. Regions of highest aesthetic quality in the FL plane

	The dimension preference is not surprising, since many natural objects have dimensions in this range. Nature is strange, but usually not totally bizarre. Some of the attractors that are most universally liked resemble well-known and easily recognizable objects. You can find many such examples in this book.
	The Lyapunov exponent preference is harder to understand, but it suggests that strongly chaotic systems are too unpredictable to be appealing. For the 443 cases that were rated 5 (best) by the evaluators, the average dimension was F = 1.30 ± 0.20, and the average Lyapunov exponent was L = 0.21 ± 0.13 bits per iterations, where the errors represent plus or minus one standard deviation. About 28% of the cases evaluated fall within both error bars. Thus this simple criterion would allow the computer to discard nearly three-quarters of the cases that are least likely to be visually appealing. This technique works in practice and was used in some cases to help select attractors to display in this book.


## What’s Left to Do?
	This book has described a new technique for generating strange attractors in unlimited numbers. A large collection of such objects offers many interesting possibilities to the artist and scientist alike. Some of these uses have already been mentioned. Others may have occurred to you as you read this book. This section leaves you with a few additional suggestions of things you might want to explore on your own.
	If your main interest is art, you probably want to produce attractors with improved spatial resolution and more colors. You can experiment with printing on different types of paper or other media. The simple linear correspondence of X, Y, Z, and W to position or color is not essential. Other mappings between the mathematical variables and the points displayed on the screen are possible. You have already seen how to project the attractors onto a sphere. You can project them onto other objects such as cylinders, tori, or even other strange attractors.
	When you have generated an attractor that appeals to you, it is natural to want to make small changes to make it even better. The coefficients in the equations are controls that you can adjust. Like knobs on your television set, they allow you to tune the attractor to get just what you want. You can change the colors without replotting the data using the PALETTE command in BASIC. You also can rotate the image to find the best angle from which to view it.
	You can produce animated strange attractors with a video camera viewing a monitor connected to the camera, or even more simply, with a photodiode connected to an oscilloscope whose screen illuminates the photodiode. This video-feedback technique has much in common with iterated maps. Each illuminated dot on the screen is mapped back to a different location after a delay determined by the propagation of the electrical and optical signals. The main control parameters are the distance, rotation, focusing, intensity, color, and hue. Some settings produce unbounded solutions—the screen goes solid black or solid white. Other settings produce a fixed-point solution with a stationary pattern. Under other conditions, periodic behavior occurs. The most interesting situation occurs when the pattern constantly changes but is not periodic, corresponding to a chaotic strange attractor. Sometimes you can perturb the system with a flash of light or by moving your hand across the field of view, causing the system to switch from one attractor to another.
	Some of the most interesting examples of computer fractals come from plotting the basin boundaries of various attractors. The basin is the set of all initial conditions that are drawn to the attractor. Sometimes these boundaries are smooth; other times they are fractals. By coloring the points just outside the basin according to the number of iterations required for them to leave some (usually large) region surrounding the attractor, beautiful escape-time fractal patterns can be produced.
	All of our attractors have such basins, and it’s not hard to program the computer to display them, but the calculations are very slow. As an example, Figure 8-5 shows in black the basin for the Hénon map. It is relatively smooth and not particularly interesting. It resembles a thick version of the attractor, but rotated by 90 degrees. Figure 8-6 shows the basin of another two-dimensional quadratic map called the Tinkerbell map. Its boundary has obvious fractal structure. In each case, the basin boundary appears to touch the attractor, suggesting that this surprising feature may be common.

Figure 8-5. Basin of attraction for the Hénon map

Figure 8-6. Basin of attraction for the Tinkerbell map

	Notice that we have now plotted the Hénon map in three different spaces. Figure 3-1 is the usual plot of the orbit in the space of the dynamical variables X and Y. Figure 8-1 is a plot in the space of the control parameters a and b. Figure 8-5 is a plot in the space of the initial conditions X0 and Y0. All of these plots are necessary to characterize the attractor completely.
	The well-known and much-studied Mandelbrot set is the set of bounded solutions in the ab plane of the mapping

	Xn+1 = Xn2 - Yn2 + a
	Yn+1 = 2XnYn + b					(Equation 8C)

The variables X and Y usually are thought of as the real and imaginary parts of a complex number Z. Each point in the ab plane has associated with it a Julia set, which is the set of all initial conditions X0 and Y0 whose solutions are bounded. The Mandelbrot set is the set of Julia sets every point of which is connected to every other point. The Julia set is named after Gaston Julia, a French mathematician who, along with Pierre Fatou, studied iterated maps in the complex plane at about the time of the first world war. Combinations of a and b at the boundary of the Mandelbrot set produce chaotic solutions, but values inside the set lead to fixed points or limit cycles. For b = 0 and Y0 = 0 (the real axis), Equation 8C reduces to a simple one-dimensional quadratic map equivalent to the logistic map.
	The Mandelbrot set has been described as the most complicated mathematical object ever seen. It may also be the ultimate computer virus, in that it takes over not only the machine (because of the large computational requirements) but also the mind of the programmer, who often becomes addicted to the beauty and variety of the patterns that it produces.
	Like the Mandelbrot set, most of the attractors produced by the programs in this book have intricate structure near the basin boundaries. You can zoom in on these regions to produce patterns that rival those produced by the Mandelbrot set. Calculation times increase markedly as you zoom in ever more closely, however.
	Much more can be done to correlate the aesthetic appeal of the attractors with the various numerical quantities that characterize them. Besides the fractal dimension and Lyapunov exponent, the system that produced them has dimension and order. Other measures of an attractor’s dimension include the capacity dimension, the information dimension, and the Lyapunov dimension. Related to the Lyapunov exponent is the entropy, which is a measure of the disorder of the system. As with the dimension, the entropy can be defined in many ways. These quantities and others are described in many of the books on fractals in the bibliography. Maps and differential equations can also be compared.
	You can test for differences between the aesthetic preferences of artists and scientists. Preliminary indications suggest that complexity might appeal more to artists than to scientists, who tend to see beauty in simplicity. There may also be discernible cultural differences. You can see how the various display techniques alter one’s preferences. For example, the use of color seems to increase the tolerance for attractors of high fractal dimension.
	Many scientific studies can be performed on a sufficiently large collection of strange attractors. The results of Table 8-1, which are merely suggestive and limited to particular types of equations, can be refined with more cases and more examples of each case. For low dimensions, maps are more chaotic than the equivalent ODEs. As the system dimension increases, however, maps become less chaotic, while ODEs become more chaotic. Equation 8A and 8B suggest that for a system dimension of about six, maps and ODEs will be equally chaotic. Will their roles reverse at higher dimension, or will the chaotic fractions asymptotically approach a universal value of about 2%?
	You can ask the same type of questions about bounded, nonchaotic solutions (fixed points, limit cycles, and tori). It is especially interesting to see how common 3-tori are in light of Peixoto’s theorem (see Section 6.6), but their production probably requires system dimensions of about 10 according to Figure 8-2, which may or may not apply to tori. Almost nothing is known about such issues.
	We have considered the fraction of the bounded, hyperdimensional control space over which chaos occurs. It is also interesting to examine the shape, location, and dimension of this chaotic region, as we did for the two-parameter Hénon map in Figure 8-1. It is likely that this region is a fractal. How does its fractal dimension depend on the system dimension and other characteristics of the system of equations? It appears that the dimension of the chaotic region is about half the dimension of the control space for the cases in this book.
	The scaling of the average fractal dimension and the Lyapunov exponent with the system dimension is intriguing and should be studied with more cases, better statistics, and more accurate calculations of the fractal dimension. You can examine statistically how the various measures of dimension compare and how these dimensions are related to the spectrum of Lyapunov exponents.
	You can look for relations between the geometrical properties of attractors and their respective power spectra. The technique can be used to explore and to quantify the various routes by which a stable solution becomes chaotic. Many such routes have been identified, such as the period-doubling exhibited by the logistic equation, but there are probably others yet to be discovered. Your role resembles that of a biologist confronted with a large variety of species, trying to classify, quantify, and study their similarities, differences, and patterns of behavior.
	Another interesting study is to search for previously unknown simple examples of chaos. Variations of the logistic equation are the simplest chaotic polynomial maps. The Lorenz and Rössler attractors are often cited as the simplest examples of chaotic polynomial ODEs. The Lorenz equations (Equation 6D) have seven terms and two quadratic nonlinearities, and the Rössler equations (Equation 6E) have seven terms and one quadratic nonlinearity.
	There are at least five different systems of chaotic, three-dimensional quadratic ODEs with five terms and two nonlinearities, and six systems with six terms and one nonlinearity. It will be left as a challenge for you to find them. There does not seem to be any chaotic system of quadratic ODEs with as few as four terms. To whet your appetite, here’s a simple chaotic system resembling the Lorenz attractor that has two fewer terms and all its coefficients equal to one:

	X' = YZ
	Y' = X -Y
	Z' = 1 - XY				(Equation 8D)

You can examine this case using the code QM7NM3NM3LM4NM2LM6. 
	Here’s another case with five terms and all unity coefficients that’s volume-preserving and thus does not have an attractor, but its solution is either a 2-torus or chaotic depending upon the initial conditions:

	X' = Y
	Y' = X + YZ
	Z" = 1 - Y2 				(Equation 8E)

It can be produced with the code QM5NM5LM5NM2NM5LM3.


##  What Good Is It?
	It is rare that a mathematical concept captivates the interest not only of scientists in diverse fields but of the general public. Chaos has done this, and it has been heralded by some as the next great revolution in science. It has ushered in a new field of experimental mathematics, sometimes pejoratively called recreational mathematics by the more traditional and often cynical older breed of mathematicians. The use of computers to produce exotic visual patterns has made difficult mathematical ideas accessible to those without extensive formal training.
	Yet it is fair to ask what it has done other than to make pretty pictures. One response is to claim that the same things were probably said about the discovery of the atomic nucleus, or electricity, or fire. We must have faith that intellectual advances will eventually yield useful applications.
	At the deepest level, an understanding of chaos alters our view of the world. Having seen the complexity that can arise from simple equations, we have reason to hope that simple equations may suffice to describe much of the complexity of the world. Difficult and long-standing problems such as fluid turbulence may eventually be understood using the ideas of chaos. Turbulence is difficult because it involves both temporal and spatial chaos and because its dimension is high. Chaos may also provide tools for making better predictions of complicated and apparently random systems, such as the weather, the stock market, earthquakes, epidemics, and population growth. It may also have applications in communications and in cryptography for devising secure codes and breaking them.
	Since chaotic systems exhibit extreme sensitivity to initial conditions, you might conclude that prediction is hopeless, but this is not the case. Prediction is hopeless for a random system or for an extremely complicated deterministic system. As the physicist Neils Bohr remarked, “Prediction is difficult, especially of the future.”  However, if the system is simple and chaotic, then the determinism can be exploited to improve short-term predictions.
	Furthermore, if the equations produce a strange attractor, as most chaotic systems do, we know that the solution lies somewhere on the attractor. Remember that an attractor occupies a negligible volume of the space in which it is embedded. Although we can’t predict where on the attractor the system will be at any particular time in the distant future, we can exclude the vast number of possible states that lie off the attractor. In meteorological terms, this might lead to eliminating the possibility of certain weather conditions with near absolute certainty.
	When we see a system in nature that behaves erratically, we are now led to wonder whether it is an example of chaos. Is simple determinism hidden in seemingly random data? This problem is opposite to the one addressed in this book. Here we have started with simple equations and produced complicated patterns. Nature presents us with complicated patterns that may or may not come from simple equations.
	Often we are given only a single fluctuating quantity sampled at discrete times—a so-called time series. The average daily temperature in New York and the daily closing Dow Jones Industrial Average are two examples of a time series. Sometimes a complicated-looking time series is simply a sum of several sine waves of different unrelated frequencies. In such a case, accurate predictions are possible using linear methods. A good example is the tides, whose behavior is not simply periodic but nevertheless can be predicted with considerable accuracy because it is governed by periodic notions of the earth and moon. More often, the time series has no such simple representation. In such a case, we would like to determine whether the behavior is random or chaotic. Chaotic systems often produce strange attractors.
	We usually don’t have data for all the variables that describe the system, nor do we even know how many there are, so we don’t know the dimension of the space in which an attractor might be embedded. Furthermore, the data record is likely to be corrupted by random noise and measurement errors. The number of data points may be small, and the system may not have reached a steady state. Finally, we usually don’t have control over the system, so we cannot directly test its sensitivity to initial conditions.
	Such a situation sounds hopeless, but progress has recently been made in testing for chaos in natural systems. For example, one can plot each data point versus its predecessor, as we did with the one-dimensional maps in Chapter 2. In some cases, this procedure is enough to reveal the determinism. More often, it is necessary to plot each data point versus several of its predecessors in a high-dimensional space. If the system is described by a strange attractor, the result is a version of the attractor called a diffeomorphism that is distorted but has the same fractal dimension. Similarly, the Lyapunov exponent can be estimated by selecting nearby points in this space and determining how rapidly they diverge from one another.
	The fractal dimension is important because the number of variables and equations is at least as large as the next higher integer, since the attractor has to be embedded in a space with dimension higher than its fractal dimension. These equations are not unique, however. Extracting equations from the data is a difficult if not impossible task, but one whose rewards justify the effort. The equations provide insight into the underlying dynamics and a means for making predictions.
	Perhaps the ultimate test for chaos is the accuracy of short-term predictions. With truly random data, prediction is impossible. Conversely, with chaotic data, there is absolute determinism, and prediction is possible in principle, at least on short-time scales dictated by the Lyapunov exponent and the precision of the data. Predictability thus precludes complete randomness and signifies determinism, although randomness and determinism often coexist. For example, the business cycle is mostly random but includes deterministic seasonal changes. The deterministic part is not necessarily chaotic, however.
	Dynamical systems are everywhere. Your body contains several. Your heart is a dynamical system whose solution normally approaches a limit cycle, but which can become chaotic when in fibrillation or a fixed point upon death. Recent research suggests that even a healthy heart beats chaotically, and a nearly periodic pattern sometimes precedes cardiac arrest.
	Other oscillations occur in your lungs, brain, and muscles. Electrocardiograms and electroencephalograms are time-series records used by doctors to deduce information about the dynamics of the corresponding organ. Some chaos in the brain may be necessary for creativity because it prevents us from repeatedly approaching the same problems in the same way. The fractal dimension of electroencephalograms has been observed to increase when a subject is engaged in mental activity. In psychology, manic depression resembles a limit cycle, and certain types of erratic behavior might be strange attractors.
	Evidence for low-dimensional strange attractors has been found in systems as diverse as the weather and climate, the business cycle, childhood epidemics, sunspots, plasma fluctuations, and even in computer models of the arms race. Some of these results should be viewed skeptically because there are many ways to be misled. The number of data points needed for an accurate determination of the dimension has been variously estimated from a pessimistic and probably overly conservative 42F to a more optimistic but still large 102 + 0.4F. If the interval between data points is too small, a fictitiously low dimension can result. Certain types of colored noise (also called fractional Brownian motion) have a degree of determinism and produce time-series records with an apparently low dimension. Many tests have been devised, such as comparing the results with those from a surrogate data set obtained by randomly shuffling the numbers in the time series.
	Chaos has a deep philosophical significance. If determinism implied perfect predictability, there would be no room for free will. We would be just small cogs in a large machine over which we have no control. It’s easy to feel insignificant in a vast and complicated universe dominated by forces too powerful to resist.
	However, chaos illustrates that determinism does not imply predictability. What is bad news for those who want to predict the weather or the stock market is good news for those who want to control them. Recall the hypothetical butterfly flapping its wings in Brazil, which sets off tornadoes in Texas. If the world is really governed by deterministic chaos, we are drastically changing the future with everything we do. We need never feel unimportant or insignificant. Who would have thought that a concept from mathematics could give meaning and purpose to our lives?
