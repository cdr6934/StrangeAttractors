[
["pieces-of-planes.html", "4 Pieces of Planes 4.1 Quadratic Maps in Two Dimensions 4.2 The Butterfly Effect Revisited 4.3 Searching the Plane 4.4 The Fractal Dimension 4.5 Higher-Order Disorder 4.6 Strange Attractor Planets 4.7 Designer Plaids 4.8 Strange Attractors that Don’t 4.9 A New Dimension in Sound", " 4 Pieces of Planes Whereas the last chapter discussed one-dimensional maps whose graphs are segments of lines, this chapter deals with two-dimensional maps whose graphs are pieces of planes and which thus produce much more interesting displays. This chapter provides the minimum tools for creating attractors that genuinely qualify as art. Armed with only the information contained here, you have such a great variety of available patterns that you hardly need to proceed beyond this chapter. But if you do stop here, you miss some delightful surprises. 4.1 Quadratic Maps in Two Dimensions In the discussion so far, the maps have involved a single variable X whose value changes with each iteration of the equation. Such maps are said to be onedimensional because the values of X can be thought of as lying along a line, and a line is a one-dimensional object. By plotting each value of X versus a previous value of X, the line can be made to wiggle with considerable complexity; but it always remains a line, and lines are of limited interest and beauty. The situation is more interesting when you consider iterated maps that involve two variables, X and Y. In such a case, each iterate produces a point in a plane, where X, by convention, represents the horizontal coordinate of the point, and Y represents the vertical coordinate. With successive iteration, the points fill in some portion of the plane. The visually interesting cases, as usual, are the chaotic ones. Such two-dimensional maps might arise, for example, from an ecological model only slightly more complicated than the logistic equation. A classic example is the predator-prey problem in which X represents the prey and Y the predator. In a simple linear model, the solution is a fixed point (a unique number of both predators and prey) or a limit cycle (both the number of predators and the number of prey oscillate, reaching their maximum values at different times, but eventually repeating). When nonlinear terms are introduced into the model, the population of each species can behave chaotically. You can think of each point that makes up such an attractor as the population of predators and prey in successive years. Since such complexity arises from these very simple models, it’s easy to understand why ecologists might have trouble predicting the fate of biological species! Perhaps the best known chaotic two-dimensional map is the Hénon map (proposed by the French astronomer Michel Hénon in 1976), whose equations are \\[ X_{n+1}=1+aX_n^2+bY_n \\] \\[ Y_{n+1}=X_n \\] The quantities a and b are the control parameters, analogous to R in the logistic equation. Hénon used the values a = -1.4 and b = 0.3. The necessary nonlinearity is provided by the X 2 term in the first equation. The Hénon map is special because the net contraction of a set of initial points covering an area of the XY plane is constant with each iteration. The area occupied by the points is 30% of the area at the previous iteration (from the bYn term). Other values of b can be used, but not all values produce chaotic solutions. Unlike the logistic map, the Hénon map is invertable; there is a unique value for Xn and Yn corresponding to each Xn+1 and Yn+1. You may have seen an alternate form of the Hénon equations in which the factor b appears instead in the second equation and the sign preceding the X2 term is negative. The result of repeated iteration of Equation 3A is shown in Figure 3-1. 3-1: The Henon map EWM?MPMMWMMMM F = 1.20 L = 0.60 The resulting graph is more than a line but less than a surface. What resembles a single line is a pair of lines, each of which is, in turn, another pair of lines, and so forth to however close you look or whatever magnification you choose. This selfsimilarity is a common characteristic of a class of objects that are called fractals. Fractals are to chaos what geometry is to algebra—the visual expression of the mathematical idea. Approaching an understanding of chaos through such visual means is appealing to those with an aversion to conventional mathematics. The Euclidean geometry we learned in high school originated with the ancient Greeks and was developed more fully by the French mathematician Descartes and others in the 1600s. It deals with simple shapes such as lines, circles, and spheres. Euclidean geometry is now being augmented by fractal geometry, whose father and champion is the contemporary mathematician, Benoit Mandelbrot. Fractals appeared in art, such as in the drawings of the Dutch artist Maurits C. Escher, before they were widely appreciated by mathematicians and scientists. Some fractals are exactly self-similar, which means that they look the same no matter how much you magnify them. Others, such as most of the ones in this book, only have regions that are self-similar. There is no part of the Hénon map where you can zoom in and find a miniature replica of the entire map. Other fractals are only statistically self-similar, which means that a magnified portion of the object has the same amount of detail as the whole, but it is not an exact replica of it. Nearly all strange attractors are fractals, but not all fractals arise from strange attractors. The Hénon map produces an object with a fractal dimension that is a fraction intermediate between one and two. The fractal dimension is a useful quantity for characterizing strange attractors. Isolated points have dimension zero, line segments have dimension one, surfaces have dimension two, and solids have dimension three. Strange attractors generally have noninteger dimensions. Some authors make a distinction between strange attractors, which have non-interger dimension, and chaotic attractors, which exhibit sensitivity to initial conditions. Since the Hénon map has X 2 as its highest-order term, it is a quadratic map. The most general two-dimensional iterated quadratic map is \\[ X_{n+1}=a_1+a_2X_n+a_3X_n^2+a_4X_nY_n+a_5Y_n+a_6Y_n^2 \\] \\[ Y_{N+1}=a_7+a_8X_n+a_9X_n^2+a_{10}X_nY_n+a_{11}Y_n+a_{12}Y_n^2 \\] The two equations in Equation 3B have 12 coefficients. For the Hénon map, \\(a_1 = 1\\), \\(a_3 = -1.4\\), \\(a_5 = 0.3\\), \\(a_8 = 1\\), and the other coefficients are zero. If we use the initial letter E to represent two-dimensional quadratic maps, the code for the Hénon map according to Table 2-1 is EWM?MPM2WM4, where we have introduced the shorthand M2 for MM and M4 for MMMM. Values of a in the range of -1.2 to 1.2 are sufficient to produce an enormous variety of strange attractors. With increments of 0.1, there are 2512 or about 6 x 1016 different cases, of which approximately 1.6% or about 1015 are chaotic. Viewing them all at a rate of one per second would require over 30 million years! Stated differently, if each one were printed on an 81/2-by-11-inch sheet of paper, the collection would cover nearly the entire land mass of Earth. Note that not all the cases are strictly distinct. For example, if you replace X with Y and Y with -X in Equation 3B, you produce an attractor rotated 90 degrees counterclockwise from the original. When you do this, be sure to change Xn+1 and Yn+1 as well as Xn and Yn. Thus the code EM4CMWJM3? produces a rotated version of the Hénon map. In the same fashion, you can rotate an attractor through 180 degrees by replacing X with -X and Y with -Y and through 270 degrees by replacing X with -Y and Y with X. Perhaps it’s easier just to rotate your computer monitor! Besides rotations, there are cases that correspond to reflections. When viewed in a mirror, the attractors have left and right reversed, but up and down remain the same. A transformation in which X is replaced with -X accomplishes this. Thus the code for a reflected Hénon map is ECM[MJM2CM4. In addition, the reflections can be rotated. Thus there are at least eight so-called degenerate states for each attractor, corresponding to rotations and reflections. Such symmetries and degeneracies play an important role in science; they often reduce the amount of work we have to do and provide relations between phenomena that initially appear different. Additional degenerate cases correspond to scale changes. For example, if you replace X by mX and Y by nY with m = n, the attractor remains the same except it is reduced in size by a factor of m. Some of the coefficients are likely to be outside the allowed range, however. The Hénon map with m = n = 2 can be generated with the code ERM1MPM2WM4. With m not equal to n, the horizontal and vertical dimensions are scaled differently, but since the computer rescales the attractor to fit the screen, the visual result is the same. These degeneracies show that there are many ways to code a particular attractor. Although this is true, there are so many different possible combinations of coefficients that it is very unlikely that two degenerate cases will be found spontaneously. Thus the examples displayed in this chapter represent but a tiny fraction of the possibilities, and you will be generating many other cases, almost none of which have been seen before. 4.2 The Butterfly Effect Revisited Two-dimensional chaotic iterated maps also exhibit sensitivity to initial conditions, but the situation is more complicated than for one-dimensional maps. Imagine a collection of initial conditions filling a small circular region of the XY plane. After one iteration, the points have moved to a new position in the plane, but they now occupy an elongated region called an ellipse. The circle has contracted in one direction and expanded in the other. With each iteration, the ellipse gets longer and narrower, eventually stretching out into a long filament. The orientation of the filament also changes with each iteration, and it wraps up like a ball of taffy. Thus two-dimensional chaotic maps have not a single Lyapunov exponent but two—a positive one corresponding to the direction of expansion, and a negative one corresponding to the direction of contraction. The signature of chaos is that at least one of the Lyapunov exponents is positive. Furthermore, the magnitude of the negative exponent has to be greater than the positive one so that initial conditions scattered throughout the basin of attraction contract onto an attractor that occupies a negligible portion of the plane. The area of the ellipse continually decreases even as it stretches to an infinite length. There is a proper way to calculate both of the Lyapunov exponents. For the mathematically inclined, the procedure involves summing the logarithms of the eigenvalues of the Jacobian matrix of the linearized transformation with occasional Gram-Schmidt reorthonormalization. This method is slightly complicated, so we will instead devise a simpler procedure sufficient for determining the largest Lyapunov exponent, which is all we need in order to test for chaos. Suppose we take two arbitrary but nearby initial conditions. The first few iterations of the map may cause the points to get closer together or farther apart, depending on the initial orientation of the two points. Eventually, the points will come arbitrarily close in the direction of the contraction, but they will continue to separate in the direction of the expansion. Thus if we wait long enough, the rate of separation will be governed only by the largest Lyapunov exponent. Fortunately, this usually takes just a few iterations. However, because the separation grows exponentially for a chaotic system, the points quickly become too far apart for an accurate estimate of the exponent. This problem can be remedied if, after each iteration, the points are moved back to their original separation along the direction of the new separation. The Lyapunov exponent is then determined by the average of the distance they must be moved for each iteration to maintain a constant small separation. If the two solutions are separated by a distance dnafter the nth iteration, and the separation after the next iteration is \\(d_{n+1}\\), the Lyapunov exponent is determined from \\[ L = \\Sigma\\frac{ log_2(\\frac{d_{n+1}}{d_n})}{N} \\] where the sum is taken over all iterations from n = 0 to n = N-1. After each iteration, the value of one of the iterates is changed to make dn+1 = dn. For the cases here, dn equals 10-6. This procedure also allows us to deal with maps of three and even higher dimensions in which there are more than two Lyapunov exponents. 4.3 Searching the Plane We now have all the tools in hand to conduct a computer search for attractors in two dimensions. The procedure is the same as for one-dimensional maps, except the Lyapunov exponent calculation is done differently and the X and Y variables are plotted as a point in the plane after each iteration. PROG06 shows the changes needed to accomplish such a search. 1000 REM TWO-D MAP SEARCH 1060 OMAX% = 2 ’Maximum order of polynomial 1070 D% = 2 ’Dimension of system 1100 SND% = 0 ’Turn sound off 1520 Y = .05 1550 XE = X + .000001: YE = Y 1590 XMIN = 1000000!: XMAX = -XMIN: YMIN = XMIN: YMAX = XMAX 1720 XNEW = A(1) + X * (A(2) + A(3) * X + A(4) * Y) 1730 XNEW = XNEW + Y * (A(5) + A(6) * Y) 1830 YNEW = A(7) + X * (A(8) + A(9) * X + A(10) * Y) 1930 YNEW = YNEW + Y * (A(11) + A(12) * Y) 2140 IF Y &lt; YMIN THEN YMIN = Y 2150 IF Y &gt; YMAX THEN YMAX = Y 2240 IF D% = 1 THEN XP = XS(I%): YP = XNEW ELSE XP = X: YP = Y 2250 IF N &lt; 1000 OR XP &lt;= XL OR XP &gt;= XH OR YP &lt;= YL OR YP &gt;= YH THEN GOTO 2320 2300 PSET (XP, YP) ’Plot point on screen 2410 IF ABS(XNEW) + ABS(YNEW) &gt; 1000000! THEN T% = 2 ’Unbounded 2470 IF ABS(XNEW - X) + ABS(YNEW - Y) &lt; .000001 THEN T% = 2 2520 Y = YNEW 2660 CODE$ = CHR$(59 + 4 * D% + O%) 2680 M% = 1: FOR I% = 1 TO D%: M% = M% * (O% + I%): NEXT I% 2910 XSAVE = XNEW: YSAVE = YNEW: X = XE: Y = YE: N = N - 1 2930 GOSUB 1700 ’Reiterate equations 2940 DLX = XNEW - XSAVE: DLY = YNEW - YSAVE 2960 DL2 = DLX * DLX + DLY * DLY 2970 IF CSNG(DL2) &lt;= 0 THEN GOTO 3070 ’Don’t divide by zero 2980 DF = 1000000000000# * DL2 2990 RS = 1 / SQR(DF) 3000 XE = XSAVE + RS * (XNEW - XSAVE): YE = YSAVE + RS * (YNEW - YSAVE) 3020 XNEW = XSAVE: YNEW = YSAVE 3030 IF DF &gt; 0 THEN LSUM = LSUM + LOG(DF): NL = NL + 1 3040 L = .721347 * LSUM / NL 3110 IF D% = 1 THEN YMIN = XMIN: YMAX = XMAX This program produces an incredible variety of interesting patterns, a small selection of which is shown in Figures 3-2 through 3-17. Admire the beauty and variety of these figures, and then make some of you own by running the program. If your computer has a printer, use the Print Screen key to print any that you find especially appealing. Figure 3-2: EAGHNFODUMJCP F 1 = 1.36 L = 0.27 Figure 3-3: EBCQAFMFVPXKQ F = 1.31 L = 0.13 Figure 3-4: EDSYVECIMGQNV F = 1.42 L = 0.03 Figure 3-5: EELXAMPXMPQOBT F = 1.55 L = 0.27 Figure 3-6: EEYYMKTUMXUVC F = 1.54 L = 0.08 Figure 3.7: EJTTSMBOGLLQF F = 1.37 L = 0.23 Figure 3.8: ENNMJRCTVVTYG F = 1.07 L = 0.01 Figure 3.9: EOVGFJKDHSAJU F = 1.38 L = 0.24 Figure 3.10: EQKOCSIDVTPGY F = 1.60 L = 0.34 Figure 3.11: EQLOIARXYGHAJ F = 1.47, L = 0.06 Figure 3.12: ETJUBWEDNRORR F = 1.42, L = 0.16 Figure 3.13: ETSILUNDQSIFA F = 1.45, L = 0.17 Figure 3.14: EUEBJLCDISIIQ F = 1.25, L = 0.24 Figure 3.15: EVDOTLRBKTJD F = 1.54, L = 0.04 Figure 3.16: EWLKPSMOGIGS F = 1.30, L = 0.02 Figure 3.17: EZPMSGCMFRENG F = 1.67, L = 0.29 If you are an experienced programmer, you might consider writing a screensaver program based on PROG06. Such a terminate-and-stay-resident (TSR) program is run once when the computer is turned on and leaves a portion of itself in memory, constantly monitoring keyboard and mouse activity. When there is no user activity for, say, five minutes, it blanks the screen and begins displaying a succession of unique strange attractors to prevent screen burn-in. The original screen is restored whenever a key is pressed or the mouse is moved. PowerBASIC version 3.0 allows you to do this easily by inserting the program between POPUP statements. 4.4 The Fractal Dimension The previous figures differ considerably in how densely they fill the plane. Some are very thin, others are thick. A good contrast is provided by Figures 3-16 and 3-17. Figure 3-16 resembles a piece of string that has been laid down in a complicated shape on the page, whereas Figure 3-17 looks like a twisted piece of paper with many holes in it. Thus the object in Figure 3-16 has a fractal dimension close to 1, and the object in Figure 3-17 has a fractal dimension closer to 2. It is possible to be more explicit and to calculate the fractal dimension exactly. Consider two simple cases, one in which successive iterates lie uniformly along a straight line that goes diagonally across the page, and the other in which successive iterates gradually fill the entire plane, as if they were grains of pepper sprinkled on the paper from a great height. The first case has dimension 1, and the second has dimension 2. How would we calculate the dimension, given the X and Y coordinates of an arbitrary collection of such points? One method is to draw a small circle somewhere on the plane that surrounds at least one of the points. We then draw a second circle with the same center but with twice the radius. Now we count the number of points inside each circle. Let’s say the smaller circle encloses N1 points and the larger circle encloses N2 points. Obviously N2 is greater than or equal to N1 because all the points inside the inner circle are also inside the outer circle. If the points are widely separated, then N2 equals N1. If the points are part of a straight line, the larger circle on average encloses twice as many points as the smaller circle, but if the points are part of a plane, the larger circle on average encloses four times as many points as the smaller circle, because the area of a circle is proportional to the square of its radius. Thus for these simple cases the dimension is given by \\[ F = log_2(\\frac{N_2}{N_1}) \\] It is hardly surprising that if you do this operation for the cases shown in the figures, the quantity F is neither 0 nor 1 nor 2 but rather a fraction. With real data, a number of practical considerations determine the accuracy of the result and the amount of computation required to obtain it: Is a circle the best shape, or would a square, rectangle, triangle, or some other shape be better? How large should the circle be? Is doubling the size of the circle optimal, or would some other factor be better? Where should the circles be placed, and how many circles are required to obtain a representative average? How many points are needed to produce a reliable fractal dimension? Let’s address each of these questions in turn. There is nothing special about circles. A rectangle, triangle, or any other two dimensional figure would suffice, because the area scales as the square of the linear dimension in each case. However, a circle is convenient because it is easy to tell whether a given point is in its interior by comparing the radius of the circle with the distance of the point from its center. The optimum size of the circle represents a compromise. Ideally, the circles should be invisibly small, because the dimension is defined in the limit of infinite resolution. However, if the circles are too small, they contain too few points to produce a statistically meaningful result, unless an unreasonably large number of iterations is performed. We somewhat arbitrarily use circles with a radius equal to about 2% of the diagonal of the smallest rectangle that contains the attractor. Similarly, doubling the radius of the circle is arbitrary. Small values degrade the statistics, and large values miss too much of the fine-scale structure. We will use a value of ten, with the smaller circle about 0.6% the size of the attractor and the larger circle about 6% the size of the attractor. Thus in Equation 3D we will use logarithms of base 10 (log10) instead of base 2 (\\(log_2\\)). Ideally, the circles should be placed uniformly or randomly over the plane. However, if we were to do this, most of the circles would be empty, and a very long calculation would be required to obtain an accurate estimate of the dimension. Instead, we center the circles on the data points themselves. In this way the circles tend to enclose many points. However, it represents a different type of average because it weighs more heavily the portions of the attractor where the points are most dense. Technically, what we are calculating is called the correlation dimension, because it involves the number of other points that are correlated with each point in the data set. The correlation dimension is never greater than the fractal dimension, but it tends not to be much smaller either. The correlation dimension is only one of many ways to define the dimension of an attractor. The various methods differ in how the regions of the attractor are weighed in the average. It is probably the easiest method to implement, and it gives more reliable results than the fractal dimension when the dimension of the attractor is greater than about two. The fractal dimension is also called the capacity dimension, and it is closely related to the Hausdorff-Besicovitch dimension. Furthermore, the correlation dimension is probably a more meaningful measure of the strangeness of the attractor, because it includes information about its formation as well as its final appearance. The number of data points required to provide an accurate estimate of the dimension is a question still being debated in the scientific literature. Therefore, we will use a heuristic approach and continually update the dimension estimate with each iteration, giving you an opportunity to decide when it seems to have converged to a unique value. To do this, we must modify the procedure slightly. Rather than count the number of data points within a circle, which would require that the calculation run to conclusion with the coordinates of all the points saved, we use the equivalent method of determining the probability that two randomly chosen points are within a certain distance of one another. To do this, the distance of each new iterate from one of its randomly chosen predecessors is calculated. Now you see why we bothered to save the last 500 iterates! We exclude the most recent 20 points, because the iterates are likely to be abnormally highly correlated with their recent predecessors. Thus, with each iteration, we have only one additional calculation to do in which we compare the distance of the iterate to one of its randomly chosen predecessors and increment N1 and N2, as appropriate. PROG07 shows the changes needed to calculate and display the fractal dimension. 1000 REM TWO-D MAP SEARCH (With Fractal Dimension) 1020 DIM XS(499), YS(499), A(504), V(99) 1580 P% = 0: LSUM = 0: N = 0: NL = 0: N1 = 0: N2 = 0 1620 TWOD% = 2 ^ D% 2210 XS(P%) = X: YS(P%) = Y 2440 GOSUB 3900 ’Calculate fractal dimension 3030 LSUM = LSUM + LOG(DF): NL = NL + 1 3060 IF N &gt; 1000 AND N MOD 10 = 0 THEN LOCATE 1, 76: PRINT USING “##.##”; L; 3170 XL = XMIN - MX: XH = XMAX + MX: YL = YMIN - MY: YH = YMAX + 1.5 * MY 3190 YH = YH - .5 * MY 3400 LOCATE 1, 1: PRINT CODE$ 3420 LOCATE 1, 63: PRINT “F =”: LOCATE 1, 73: PRINT “L =” 3900 REM Calculate fractal dimension 3910 IF N &lt; 1000 THEN GOTO 4010 ’Wait for transient to settle 3920 IF N = 1000 THEN D2MAX = (XMAX - XMIN) ^ 2 + (YMAX - YMIN) ^ 2 3930 J% = (P% + 1 + INT(480 * RND)) MOD 500 3940 DX = XNEW - XS(J%): DY = YNEW - YS(J%) 3950 D2 = DX * DX + DY * DY 3960 IF D2 &lt; .001 * TWOD% * D2MAX THEN N2 = N2 + 1 3970 IF D2 &gt; .00001 * TWOD% * D2MAX THEN GOTO 4010 3980 N1 = N1 + 1 3990 F = .434294 * LOG(N2 / (N1 - .5)) 4000 LOCATE 1, 66: PRINT USING “##.##”; F; 4010 RETURN 4.5 Higher-Order Disorder 4.6 Strange Attractor Planets 4.7 Designer Plaids 4.8 Strange Attractors that Don’t 4.9 A New Dimension in Sound "]
]
